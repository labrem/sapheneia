# Sapheneia TimesFM Project Documentation

This document provides a comprehensive overview of the Sapheneia TimesFM project, including the TimesFM model, the project's codebase, and opportunities for code optimization.

## 1. The TimesFM Model

TimesFM is a decoder-only foundation model for time-series forecasting, pre-trained on 100 billion real-world time-points. It is a powerful and versatile model that can be adapted to a wide range of forecasting tasks.

### 1.1. Model Parameters

The TimesFM model is configured with the following parameters:

| Parameter | Description | Type | Default |
|---|---|---|---|
| `context_len` | The length of the historical data (context window) that the model uses to make predictions. | integer | 512 |
| `horizon_len` | The length of the forecast horizon, indicating how many future time steps the model will predict. | integer | 24 |
| `input_patch_len` | The fixed length of the input patches that the model processes. | integer | 32 |
| `output_patch_len` | The fixed length of the output patches generated by the model during forecasting. | integer | 128 |
| `num_layers` | The number of stacked transformer layers within the model's architecture. | integer | 20 |
| `model_dims` | The dimensionality of the model. | integer | 1280 |
| `freq` | A categorical indicator for the frequency of the input time series. 0 for high frequency (e.g., daily), 1 for medium frequency (e.g., weekly, monthly), or 2 for low frequency (e.g., quarterly, yearly). | integer | 0 |
| `repo_id` | The Hugging Face repository ID of the pre-trained model. | string | "google/timesfm-1.0-200m" |

### 1.2. Model Inputs

The TimesFM model takes the following inputs for forecasting:

| Input | Description | Type |
|---|---|---|
| `inputs` | The input time series data. This can be a single series or a batch of series. | List[float] or List[List[float]] |
| `freq` | The frequency of the input time series. | integer or List[integer] |
| `dynamic_numerical_covariates` | A dictionary of dynamic numerical covariates. | Dict[str, List[List[float]]] |
| `dynamic_categorical_covariates` | A dictionary of dynamic categorical covariates. | Dict[str, List[List[str]]] |
| `static_numerical_covariates` | A dictionary of static numerical covariates. | Dict[str, List[float]] |
| `static_categorical_covariates` | A dictionary of static categorical covariates. | Dict[str, List[str]] |

### 1.3. Model Outputs

The TimesFM model produces the following outputs:

| Output | Description | Type |
|---|---|---|
| `point_forecast` | The point forecast for the specified horizon. | numpy.ndarray |
| `quantile_forecast` | The quantile forecasts for the specified horizon. | numpy.ndarray |

### 1.4. Output Quantiles

Index 0: A Mean Forecast (seems to be a legacy output)
Index 1: The 10th Quantile (0.1)
Index 2: The 20th Quantile (0.2)
Index 3: The 30th Quantile (0.3)
Index 4: The 40th Quantile (0.4)
Index 5: The 50th Quantile (0.5)
Index 6: The 60th Quantile (0.6)
Index 7: The 70th Quantile (0.7)
Index 8: The 80th Quantile (0.8)
Index 9: The 90th Quantile (0.9)

## 2. Codebase Overview

The Sapheneia TimesFM project is structured into three main components:

*   `/src`: A Python library containing the core logic for data processing, forecasting, model handling, and visualization.
*   `/webapp`: A Flask-based web application that provides a user interface for the forecasting tools.
*   `/notebooks`: Jupyter notebooks for research, demos, and experimentation.

This modular structure separates the core functionality from the user interface, which is a good practice for code maintainability and reusability.

## 3. Code Optimization Opportunities

While the codebase is well-structured, there are several opportunities to consolidate redundant code and improve efficiency. The `sapheneia_webapp_mirror.ipynb` notebook, while useful for debugging, duplicates a significant amount of logic from the `webapp/app.py` file.

The following is a list of opportunities for code consolidation:

*   **Model Initialization:** The model initialization logic in `webapp/app.py` and `sapheneia_webapp_mirror.ipynb` can be centralized into a single function or class in `src/model.py`. This function could take the model configuration as input and return an initialized model object.

*   **Data Processing:** The data loading and processing logic can be further abstracted. A single function in `src/data.py` could handle the entire data processing pipeline, from loading the CSV file to preparing the data for forecasting.

*   **Forecasting:** The forecasting logic, including the handling of covariates and quantiles, can be consolidated into a single function in `src/forecast.py`. This function would take the processed data and forecasting parameters as input and return the forecast results.

*   **Visualization:** The visualization logic can be centralized in `src/visualization.py`. A single function could take the forecast results and generate the appropriate visualizations.

*   **Quantile Processing:** The logic for processing quantiles and creating quantile bands is a prime candidate for consolidation. This logic is currently duplicated in both the web app and the notebook. A new function in `src/forecast.py` or `src/visualization.py` could be created to handle this task.

By consolidating this redundant code, the project will be easier to maintain, debug, and extend in the future.

## 4. Code Optimization Implementation Plan

This section outlines a step-by-step plan to implement the code optimizations identified in Section 3. The goal is to centralize redundant logic from `webapp/app.py` and `notebooks/sapheneia_webapp_mirror.ipynb` into the `src/` library.

### Step 1: Centralize Model Initialization

1.  **Modify `src/model.py`:**
    *   Create a new function `initialize_timesfm_model` that accepts `backend`, `context_len`, `horizon_len`, `checkpoint`, and `local_model_path`.
    *   This function will encapsulate the complete model loading and initialization process, including the creation of `TimesFMModel`, `Forecaster`, and `Visualizer` objects.
    *   It will return a tuple: `(model_wrapper, forecaster, visualizer)`.

2.  **Refactor `webapp/app.py`:**
    *   In `api_init_model`, replace the current initialization logic with a call to `initialize_timesfm_model` from `src/model.py`.
    *   Store the returned objects in the global `current_model`, `current_forecaster`, and `current_visualizer` variables.

3.  **Refactor `notebooks/sapheneia_webapp_mirror.ipynb`:**
    *   In the "Model Initialization" section, remove the duplicated code and call the new `initialize_timesfm_model` function.

### Step 2: Consolidate Data Processing

1.  **Enhance `src/data.py`:**
    *   The existing `load_csv_data` function is already a good abstraction.
    *   The `prepare_forecast_data` function will be enhanced to be more generic if needed, but it already handles the main logic of preparing data for forecasting. No major changes are needed here for now, but we will ensure both the webapp and notebook use it consistently.

2.  **Refactor `webapp/app.py` and `notebooks/sapheneia_webapp_mirror.ipynb`:**
    *   Ensure that both files use `DataProcessor().load_csv_data(...)` and `DataProcessor().prepare_forecast_data(...)` without re-implementing any of that logic.

### Step 3: Abstract Forecasting Logic

1.  **Create `run_forecast` in `src/forecast.py`:**
    *   Create a new function `run_forecast` that takes `forecaster`, `target_inputs`, `covariates`, `use_covariates`, and `freq` as arguments.
    *   This function will implement the logic to decide whether to run `forecast_with_covariates` or the basic `forecast`, including the fallback mechanism currently present in `webapp/app.py`.
    *   It will return a dictionary containing the forecast results (e.g., `{'enhanced_forecast': ..., 'quantile_forecast': ...}`).

2.  **Refactor `webapp/app.py`:**
    *   In the `api_forecast` endpoint, replace the forecasting logic with a call to the new `run_forecast` function.

3.  **Refactor `notebooks/sapheneia_webapp_mirror.ipynb`:**
    *   In the "Forecasting" section, replace the duplicated forecasting logic with a call to `run_forecast`.

### Step 4: Centralize Quantile Processing

1.  **Create `process_quantile_bands` in `src/forecast.py`:**
    *   Create a new function `process_quantile_bands` that accepts the `quantile_forecast` array and a list of `selected_indices`.
    *   This function will contain the logic for sorting quantiles and creating the quantile band dictionary, as seen in `webapp/app.py` and the notebook.
    *   It will return a dictionary of quantile bands ready for visualization.

2.  **Refactor `webapp/app.py`:**
    *   In `api_visualize`, use `process_quantile_bands` to generate the `intervals` dictionary.

3.  **Refactor `notebooks/sapheneia_webapp_mirror.ipynb`:**
    *   In the "Quantile Processing" section, call `process_quantile_bands` to generate the quantile bands.

### Step 5: Streamline Visualization

1.  **Enhance `src/visualization.py`:**
    *   The `plot_forecast_with_intervals` function is already well-abstracted. No changes are needed for this function itself.
    *   We will ensure that the data preparation for this function is clean in both the webapp and notebook.

2.  **Refactor `webapp/app.py` and `notebooks/sapheneia_webapp_mirror.ipynb`:**
    *   After getting the results from `run_forecast` and `process_quantile_bands`, the calls to `plot_forecast_with_intervals` should be straightforward and clean in both files.

By following these steps, we will significantly reduce code duplication, improve maintainability, and make the codebase more robust and easier to extend.