
# Sapheneia TimesFM Project Documentation

This document provides a comprehensive overview of the Sapheneia TimesFM project, including the TimesFM model, the project's codebase, and opportunities for code optimization.

## 1. The TimesFM Model

TimesFM is a decoder-only foundation model for time-series forecasting, pre-trained on 100 billion real-world time-points. It is a powerful and versatile model that can be adapted to a wide range of forecasting tasks.

### 1.1. Model Parameters

The TimesFM model is configured with the following parameters:

| Parameter | Description | Type | Default |
|---|---|---|---|
| `context_len` | The length of the historical data (context window) that the model uses to make predictions. | integer | 512 |
| `horizon_len` | The length of the forecast horizon, indicating how many future time steps the model will predict. | integer | 24 |
| `input_patch_len` | The fixed length of the input patches that the model processes. | integer | 32 |
| `output_patch_len` | The fixed length of the output patches generated by the model during forecasting. | integer | 128 |
| `num_layers` | The number of stacked transformer layers within the model's architecture. | integer | 20 |
| `model_dims` | The dimensionality of the model. | integer | 1280 |
| `freq` | A categorical indicator for the frequency of the input time series. 0 for high frequency (e.g., daily), 1 for medium frequency (e.g., weekly, monthly), or 2 for low frequency (e.g., quarterly, yearly). | integer | 0 |
| `repo_id` | The Hugging Face repository ID of the pre-trained model. | string | "google/timesfm-1.0-200m" |

### 1.2. Model Inputs

The TimesFM model takes the following inputs for forecasting:

| Input | Description | Type |
|---|---|---|
| `inputs` | The input time series data. This can be a single series or a batch of series. | List[float] or List[List[float]] |
| `freq` | The frequency of the input time series. | integer or List[integer] |
| `dynamic_numerical_covariates` | A dictionary of dynamic numerical covariates. | Dict[str, List[List[float]]] |
| `dynamic_categorical_covariates` | A dictionary of dynamic categorical covariates. | Dict[str, List[List[str]]] |
| `static_numerical_covariates` | A dictionary of static numerical covariates. | Dict[str, List[float]] |
| `static_categorical_covariates` | A dictionary of static categorical covariates. | Dict[str, List[str]] |

### 1.3. Model Outputs

The TimesFM model produces the following outputs:

| Output | Description | Type |
|---|---|---|
| `point_forecast` | The point forecast for the specified horizon. | numpy.ndarray |
| `quantile_forecast` | The quantile forecasts for the specified horizon. | numpy.ndarray |

## 2. Codebase Overview

The Sapheneia TimesFM project is structured into three main components:

*   **`/src`**: A Python library containing the core logic for data processing, forecasting, model handling, and visualization.
*   **`/webapp`**: A Flask-based web application that provides a user interface for the forecasting tools.
*   **`/notebooks`**: Jupyter notebooks for research, demos, and experimentation.

This modular structure separates the core functionality from the user interface, which is a good practice for code maintainability and reusability.

## 3. Code Optimization Opportunities

While the codebase is well-structured, there are several opportunities to consolidate redundant code and improve efficiency. The `sapheneia_webapp_mirror.ipynb` notebook, while useful for debugging, duplicates a significant amount of logic from the `webapp/app.py` file.

The following is a list of opportunities for code consolidation:

*   **Model Initialization:** The model initialization logic in `webapp/app.py` and `sapheneia_webapp_mirror.ipynb` can be centralized into a single function or class in `src/model.py`. This function could take the model configuration as input and return an initialized model object.

*   **Data Processing:** The data loading and processing logic can be further abstracted. A single function in `src/data.py` could handle the entire data processing pipeline, from loading the CSV file to preparing the data for forecasting.

*   **Forecasting:** The forecasting logic, including the handling of covariates and quantiles, can be consolidated into a single function in `src/forecast.py`. This function would take the processed data and forecasting parameters as input and return the forecast results.

*   **Visualization:** The visualization logic can be centralized in `src/visualization.py`. A single function could take the forecast results and generate the appropriate visualizations.

*   **Quantile Processing:** The logic for processing quantiles and creating quantile bands is a prime candidate for consolidation. This logic is currently duplicated in both the web app and the notebook. A new function in `src/forecast.py` or `src/visualization.py` could be created to handle this task.

By consolidating this redundant code, the project will be easier to maintain, debug, and extend in the future.
