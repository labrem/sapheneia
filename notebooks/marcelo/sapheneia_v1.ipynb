{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["vJ-uHZRjtfNX","MyJaRSi44ivZ","l-Yi5NrIcG_Z","aJ69Cse0X9_T","K_zEpzYSX5hg"],"authorship_tag":"ABX9TyPzVc/zCRM88hnZF/3YsF3C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Time-series sequences with TinyLlama quantized models"],"metadata":{"id":"vJ-uHZRjtfNX"}},{"cell_type":"markdown","source":["### Introduction\n","\n","- This action has been completed with the Notebook: https://github.com/labrem/sapheneia/blob/main/notebooks/marcelo/sapheneia_v1.ipynb.\n","- The following Gemini thread has been used to help build this up both conceptually and in practice: https://g.co/gemini/share/c5212fd78fad.\n","- This Notebook tests the capabilities of TinyLlama quantized models to generate raw token sequences given an input sequence.\n","- In order to speed up the model loading, the models have been stored in a local drive.\n","\n","### Accomplishments\n","\n","- With this Notebook we are able to achieve the following items.\n","    - Load and run a local drive instance of the TinyLlama model with different quantization levels (2-bit, 4-bit, 6-bit and 8-bit) on CPU as well as with GPU acceleration.\n","    - Compute the execution time for each model.\n","    - Check model behavior with different parameters such as:\n","    \n","    ```python\n","        parameters = {\n","        'max_tokens': 20, # Maximum number of output generated tokens\n","        'logprobs': 10, # Number of output token-level log probabilities\n","        'grammar': grammar, # Valid grammar for output generation\n","        'temperature': 0.9 # Temperature calibrating the 'surprise of the output generation\n","    }\n","    ```\n","    \n","    - Define a grammar such that it forces the model to output only certain to tokens such as numbers, period and comma.\n","    \n","    ```python\n","    gbnf_grammar_str = r'''\n","    root   ::= sequence\n","    sequence ::= number (\",\" number)*\n","    number ::= (\"-\")? ([0-9]+ | [0-9]+ \".\" [0-9]+)\n","    '''\n","    try:\n","        grammar = LlamaGrammar.from_string(gbnf_grammar_str)\n","        print(\"Strict grammar parsed successfully\")\n","        print(grammar)\n","    except Exception as e:\n","        print(f\"Error parsing grammar: {e}\")\n","        grammar = None\n","    ```\n","    \n","    - Understand how to output generated token log probabilities. Note how in the log-probabilities for last number in the generated sequence below, where `1`, `2` and `.` appear as the highest probabilities to be sampled by the model. Also note how characters such as `\\n` and `:` also show up in the top 10 probabilities, but is never selected in the generative process because it is not compliant with the established grammar.\n","    \n","    ```python\n","    prompt = \"1.0,2.1,3.3,4.2,5.7,\"\n","    ...\n","    ### Running q8_0\n","    \tresponse = 6.7,7.6,8.9,10.4,12.\n","    ...\n","    ... {'1': np.float32(-0.110834435),\n","    '9': np.float32(-3.750521),\n","    '2': np.float32(-4.000365),\n","    '8': np.float32(-4.487987),\n","    '7': np.float32(-5.1254697),\n","    '0': np.float32(-5.1982684),\n","    '\\n': np.float32(-5.263313),\n","    '6': np.float32(-5.366506),\n","    ' ': np.float32(-5.544479),\n","    '5': np.float32(-5.6029096)},\n","    {'2': np.float32(-0.5808073),\n","    '1': np.float32(-1.1937376),\n","    '3': np.float32(-2.658832),\n","    '0': np.float32(-3.187264),\n","    '4': np.float32(-4.535298),\n","    '5': np.float32(-5.0283246),\n","    '.': np.float32(-5.481704),\n","    '6': np.float32(-6.451225),\n","    '7': np.float32(-6.923182),\n","    '8': np.float32(-7.3887563)},\n","    {'.': np.float32(-0.03789382),\n","    ',': np.float32(-3.8787103),\n","    '\\n': np.float32(-5.5151057),\n","    ' ': np.float32(-6.6268954),\n","    ':': np.float32(-7.178901),\n","    ')': np.float32(-7.3973727),\n","    '.,': np.float32(-7.824158),\n","    ']': np.float32(-7.8326225),\n","    '-': np.float32(-7.9419684),\n","    '+': np.float32(-8.018802)}]}\n","    ```\n","\n"],"metadata":{"id":"1GJAFVeVbcCn"}},{"cell_type":"markdown","source":["# setup"],"metadata":{"id":"MyJaRSi44ivZ"}},{"cell_type":"markdown","source":["I struggled with the installation witb GPU support, only able to fix from https://gemini.google.com/app/f3ec74b59f92f56f"],"metadata":{"id":"jv4-ObJ0vNAY"}},{"cell_type":"code","source":["import os\n","import torch\n","import time\n","import numpy as np\n","import math"],"metadata":{"id":"KIAlg7zwwBQx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wxnJ_0lbpRI","executionInfo":{"status":"ok","timestamp":1752157539209,"user_tz":240,"elapsed":14917,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"903376bc-c48c-40ee-9251-e66e908ca891"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive/',force_remount=True)\n","\n","path = '/content/drive/MyDrive/dev/'"]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    print(f\"CUDA version: {torch.version.cuda}\")"],"metadata":{"id":"hKWzSoacyzVA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    !nvcc --version"],"metadata":{"id":"39DwOAqkwUMM","executionInfo":{"status":"ok","timestamp":1752158012791,"user_tz":240,"elapsed":77,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    !nvidia-smi"],"metadata":{"id":"vQ1iBvVmwXjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Uninstall any existing version to ensure a clean slate\n","print(\"Uninstalling existing llama-cpp-python to ensure a clean install...\")\n","!pip uninstall -y llama-cpp-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4poVZ-4wKiZ","executionInfo":{"status":"ok","timestamp":1752158186264,"user_tz":240,"elapsed":1527,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"4c7269d9-f5e8-4d5b-e865-90e46aacfac0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Uninstalling existing llama-cpp-python to ensure a clean install...\n","Found existing installation: llama_cpp_python 0.3.12\n","Uninstalling llama_cpp_python-0.3.12:\n","  Successfully uninstalled llama_cpp_python-0.3.12\n"]}]},{"cell_type":"code","source":["# Check if a CUDA-enabled GPU is available\n","if torch.cuda.is_available():\n","    print(\"GPU detected. Installing the CUDA-enabled version of llama-cpp-python ...\")\n","    # This command will install the version compatible with the Colab GPU's CUDA version\n","    # The --no-cache-dir flag helps ensure a fresh download\n","    !pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124 --no-cache-dir\n","else:\n","    print(\"No GPU detected. Installing the CPU-only version of llama-cpp-python ...\")\n","    # This is the standard command for a CPU-only installation\n","    !pip install llama-cpp-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5B_TKSZKv58l","executionInfo":{"status":"ok","timestamp":1752158558474,"user_tz":240,"elapsed":370692,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"6b12beea-160a-4d1e-8110-25c5aed65bc6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["No GPU detected. Installing the CPU-only version of llama-cpp-python...\n","Collecting llama-cpp-python\n","  Downloading llama_cpp_python-0.3.12.tar.gz (49.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.14.1)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (2.0.2)\n","Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (5.6.3)\n","Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n","Building wheels for collected packages: llama-cpp-python\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.12-cp311-cp311-linux_x86_64.whl size=4158990 sha256=1b10f98c7fee773cf0f535ebecfa18f81608c14d874013c6853c0d995ea9e3e4\n","  Stored in directory: /root/.cache/pip/wheels/7d/b8/30/8988efe892bf4e389f95fa946371363596b28a47091f12494c\n","Successfully built llama-cpp-python\n","Installing collected packages: llama-cpp-python\n","Successfully installed llama-cpp-python-0.3.12\n"]}]},{"cell_type":"code","source":["# Verify the installation\n","try:\n","    from llama_cpp import Llama, LlamaGrammar\n","    print(\"llama-cpp-python imported successfully!\")\n","except Exception as e:\n","    print(f\"Error importing llama-cpp-python: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qTFksP_ov5_O","executionInfo":{"status":"ok","timestamp":1752158610262,"user_tz":240,"elapsed":25,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"3270d610-aac3-4f13-f8fc-4316f338f18f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["llama-cpp-python imported successfully!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JWGtWG4pwgR2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1CYgHnHj04a","executionInfo":{"status":"ok","timestamp":1752071092348,"user_tz":240,"elapsed":113,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"25ae542f-d5dc-41a3-fc07-cdeb14784066"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_CoVdixj06w","executionInfo":{"status":"ok","timestamp":1752071093757,"user_tz":240,"elapsed":206,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"857a7a60-d65e-4ea2-f7ab-3c2efec61c4b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jul  9 14:24:53 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n","| N/A   40C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# Install the pre-built wheel for CUDA 12.4\n","!pip uninstall -y llama-cpp-python\n","!pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu124"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4vo-v8YGlU6","executionInfo":{"status":"ok","timestamp":1752157587005,"user_tz":240,"elapsed":47797,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"96686acf-e6a0-4871-dcab-1003d8dcb748"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping llama-cpp-python as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu124\n","Collecting llama-cpp-python\n","  Downloading https://github.com/abetlen/llama-cpp-python/releases/download/v0.3.12-cu124/llama_cpp_python-0.3.12-cp311-cp311-linux_x86_64.whl (504.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.6/504.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.14.1)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (2.0.2)\n","Collecting diskcache>=5.6.1 (from llama-cpp-python)\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n","Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: diskcache, llama-cpp-python\n","Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.12\n"]}]},{"cell_type":"markdown","source":["# models"],"metadata":{"id":"l-Yi5NrIcG_Z"}},{"cell_type":"markdown","source":["## n_gpu_layers"],"metadata":{"id":"aJ69Cse0X9_T"}},{"cell_type":"markdown","source":["* This Notebook is just to test running various quantized TinyLlama models\n","\n","* As a result, we will either use either n_gpu_layers = 0 (for running on CPU only) or n_gpu_layers = 33 (33 GPU layers)\n","\n","* Refer to the Gemini explanation below in order to optimize n_gpu_layers when running the code for getting results"],"metadata":{"id":"grecOm2eYMPe"}},{"cell_type":"code","source":["# Check if a CUDA-enabled GPU is available\n","if torch.cuda.is_available():\n","    n_gpu_layers = 33 # GPU\n","else:\n","    n_gpu_layers = 0 # CPU"],"metadata":{"id":"QoMjMcI6Wv9s","executionInfo":{"status":"ok","timestamp":1752158677215,"user_tz":240,"elapsed":36,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["https://g.co/gemini/share/1de12d982e5f\n","\n","That's an excellent and very important question for getting the best performance out of your models. Setting `n_gpu_layers` is the primary way you control the balance between CPU and GPU work.\n","\n","Here’s a breakdown of what it means and how to find the optimal value for your specific system.\n","\n","### What `n_gpu_layers` Does\n","\n","This parameter determines how many layers of the neural network are \"offloaded\" to your GPU's VRAM.\n","\n","  * **CPU:** Your computer's main processor. It has access to a large amount of slower system RAM.\n","  * **GPU:** Your graphics card. It has a smaller amount of very fast video RAM (VRAM) and is designed for the massive parallel calculations that LLMs require.\n","\n","**The trade-off is simple:**\n","\n","  * **More layers on the GPU (`n_gpu_layers` is high):** Inference (generating text) is much faster.\n","  * **Fewer layers on the GPU (`n_gpu_layers` is low):** More work is done on the slower CPU, but it uses less of your precious VRAM.\n","\n","The \"optimal\" value is therefore: **The maximum number of layers you can fit into your GPU's VRAM without causing errors, while leaving a small buffer for your operating system.**\n","\n","-----\n","\n","### How to Find the Optimal Value: A Practical Guide\n","\n","The best way to find the perfect number is through a bit of experimentation. Here is a simple, effective process:\n","\n","#### Step 1: Know Your Total VRAM\n","\n","First, check how much VRAM your GPU has.\n","\n","  * **On Windows:** Open the Task Manager, go to the \"Performance\" tab, and click on your GPU. Look for \"Dedicated GPU Memory\".\n","  * **On Linux (with NVIDIA):** Open a terminal and run the command `nvidia-smi`. It will show you your GPU's total memory (e.g., `8192MiB`).\n","\n","#### Step 2: Start High and Let the Model Tell You\n","\n","You don't need to guess the number of layers. The easiest method is to set `n_gpu_layers` to a very high number. The `llama-cpp-python` library is smart enough to only offload as many layers as it can actually fit.\n","\n","Modify your model loading code like this:\n","\n","```python\n","from llama_cpp import Llama\n","\n","llm = Llama(\n","    model_path=\"/path/to/your/model.gguf\",\n","    # Set a very high number to offload as many layers as possible\n","    n_gpu_layers=999,  # <--- START WITH A HIGH NUMBER\n","    n_ctx=2048,\n","    verbose=True  # <--- Set to True to see the loading output\n",")\n","```\n","\n","#### Step 3: Observe the Output\n","\n","When you run this code, `llama.cpp` will print detailed information as it loads the model. Look for a line that looks like this:\n","\n","```\n","llama_model_load_internal: offloaded 33 of 33 layers to GPU\n","```\n","\n","or\n","\n","```\n","llm_load_tensors: offloaded 33/33 layers to GPU\n","```\n","\n","**That number is your answer.** In this example, the model has 33 layers, and all of them fit into your VRAM. Your optimal `n_gpu_layers` is **33**. You can then set `n_gpu_layers=33` in your code for future runs to be precise.\n","\n","#### What If It Crashes?\n","\n","If you set the number too high manually and your system becomes unstable or the program crashes with a \"CUDA out of memory\" error, it means you've exceeded your VRAM. In that case, simply lower the number and try again. For example, if `n_gpu_layers=33` crashes, try `30`, then `28`, until you find a stable number.\n","\n","**Pro Tip:** Often, the last one or two layers of a model can be disproportionately large. If you find that offloading all layers works but your computer feels sluggish, try reducing the number by 1 or 2 (e.g., `n_gpu_layers=31` instead of `33`). This leaves a bit more VRAM for your operating system and can lead to a smoother overall experience with a negligible impact on performance.\n","That's an excellent and very practical question. Finding the optimal `n_gpu_layers` is the key to getting the best performance out of your hardware. Here’s a breakdown of what it means and how to find the best value for your specific setup.\n","\n","### What `n_gpu_layers` Does\n","\n","This parameter controls how many layers of the model are \"offloaded\" from your system's RAM to the GPU's dedicated, high-speed VRAM.\n","\n","  * **`n_gpu_layers = 0`**: The entire model runs on your CPU. This is the slowest option but uses the least VRAM.\n","  * **`n_gpu_layers > 0`**: The specified number of layers are moved to the GPU. Since GPUs are massively parallel, they can process these layers much faster than a CPU, leading to a significant speedup in generating tokens.\n","  * **The Goal**: Offload as many layers as possible to the GPU without running out of VRAM.\n","\n","### The Trade-Off: Speed vs. VRAM\n","\n","The main limiting factor is your GPU's VRAM capacity. Each layer you offload consumes a chunk of VRAM. If you try to offload more layers than your VRAM can hold, the program will crash with an out-of-memory error.\n","\n","The performance gain is not linear. The bulk of the computation happens in the middle layers. Offloading the first few layers gives a huge speed boost. Continuing to offload more layers gives diminishing returns, but is still faster.\n","\n","### How to Find the Optimal Value: A Simple Experiment\n","\n","The best way to find the ideal number is to test it empirically.\n","\n","**Step 1: Start High**\n","\n","The easiest way to start is to set `n_gpu_layers` to a very large number, like `-1` or `999`. The `llama-cpp-python` library is smart enough to know this means \"offload as many layers as you possibly can\".\n","\n","```python\n","# Try to offload all layers\n","llm = Llama(\n","    model_path=\"path/to/your/model.gguf\",\n","    n_gpu_layers=-1, # -1 means \"all possible layers\"\n","    verbose=True # Set to True to see the loading output\n",")\n","```\n","\n","**Step 2: Watch the Output During Loading**\n","\n","When the model loads with `verbose=True`, it will print detailed information. Look for a line that looks like this:\n","\n","`llama_model_load_internal: offloaded 33 of 33 layers to GPU`\n","\n","This tells you the maximum number of layers the model has (`33` in this case) and how many it successfully moved to the GPU. **The number it successfully offloaded is your practical maximum.**\n","\n","**Step 3: Monitor Your VRAM**\n","\n","While the model is loaded, open your system's GPU monitoring tool:\n","\n","  * **NVIDIA GPUs**: Use `nvidia-smi` in your command line/terminal.\n","  * **AMD GPUs**: Use `radeontop` or the monitoring utility in your driver software.\n","  * **Windows**: The Performance tab in the Task Manager (select your GPU).\n","\n","Check how much VRAM is being used. If it's very close to the maximum (e.g., 7.8GB / 8.0GB), you are at the limit.\n","\n","**Step 4: Fine-Tune if Necessary**\n","\n","  * **If it crashes with an \"out of memory\" error:** Your GPU can't handle all the layers. Reduce the number. If the model has 33 layers, try `n_gpu_layers=28`, then `25`, and so on, until it loads successfully.\n","  * **If it loads but VRAM is maxed out:** You've found a good value. You might want to reduce it by 1 or 2 layers (`n_gpu_layers=31` instead of `33`) just to leave a little breathing room for your operating system or other applications, which can prevent stuttering.\n","\n","**In summary, the ideal `n_gpu_layers` is the highest number you can set without running out of VRAM.** The \"set it to -1 and see what happens\" method is the quickest way to find that number.\n"],"metadata":{"id":"Io9oRqGkYBqX"}},{"cell_type":"markdown","source":["## models"],"metadata":{"id":"K_zEpzYSX5hg"}},{"cell_type":"markdown","source":["https://g.co/gemini/share/5e6bc8594d7d\n","\n"],"metadata":{"id":"807bsTmVZ91H"}},{"cell_type":"code","source":["model_path = path+\".models/tinyllama-1.1b-chat-v1.0.Q2_K.gguf\"\n","generator_q2_k = Llama(\n","    model_path=model_path,\n","    chat_format=\"disabled\",  # This prevents the model from wrapping input in chat templates\n","    n_ctx=2048,\n","    n_threads=2,\n","    n_gpu_layers=n_gpu_layers,\n","    logits_all=True,\n","    verbose=False,\n",")"],"metadata":{"id":"CK2dMnRlAovw","executionInfo":{"status":"ok","timestamp":1752158695907,"user_tz":240,"elapsed":10347,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b0b539d-d27b-488e-d3b9-86de22e8a6ce"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n"]}]},{"cell_type":"code","source":["# Check the number of layers offloaded to the GPU\n","offloaded_layers = generator_q2_k.model_params.n_gpu_layers\n","print(f\"✅ Successfully offloaded {offloaded_layers} layers to the GPU\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LgJ6G56DB7XL","executionInfo":{"status":"ok","timestamp":1752158695944,"user_tz":240,"elapsed":30,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"678ca63a-6f75-4610-ea6a-fa9bdffac8b4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Successfully offloaded 0 layers to the GPU\n"]}]},{"cell_type":"code","source":["model_path = path+\".models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf\"\n","generator_q4_k_m = Llama(\n","    model_path=model_path,\n","    chat_format=\"disabled\",  # This prevents the model from wrapping input in chat templates\n","    n_ctx=2048,\n","    n_threads=2,\n","    n_gpu_layers=n_gpu_layers,\n","    logits_all=True,\n","    verbose=False,\n",")"],"metadata":{"id":"u_V5LFII9rhI","executionInfo":{"status":"ok","timestamp":1752158707379,"user_tz":240,"elapsed":11434,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6c7052d5-2355-4ae0-925c-fa5ae59b59d6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n"]}]},{"cell_type":"code","source":["# Check the number of layers offloaded to the GPU\n","offloaded_layers = generator_q4_k_m.model_params.n_gpu_layers\n","print(f\"✅ Successfully offloaded {offloaded_layers} layers to the GPU\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eO-rWZvZIeJl","executionInfo":{"status":"ok","timestamp":1752158707396,"user_tz":240,"elapsed":12,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"9696564b-e069-411a-b28f-1bcc52deb66a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Successfully offloaded 0 layers to the GPU\n"]}]},{"cell_type":"code","source":["model_path = path+\".models/tinyllama-1.1b-chat-v1.0.Q6_K.gguf\"\n","generator_q6_k = Llama(\n","    model_path=model_path,\n","    chat_format=\"disabled\",  # This prevents the model from wrapping input in chat templates\n","    n_ctx=2048,\n","    n_threads=2,\n","    n_gpu_layers=n_gpu_layers,\n","    logits_all=True,\n","    verbose=False,\n",")"],"metadata":{"id":"YK1EZOydZ_ic","executionInfo":{"status":"ok","timestamp":1752158721683,"user_tz":240,"elapsed":14283,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b35af032-f207-4e06-e8b8-ec154901bf11"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n"]}]},{"cell_type":"code","source":["# Check the number of layers offloaded to the GPU\n","offloaded_layers = generator_q6_k.model_params.n_gpu_layers\n","print(f\"✅ Successfully offloaded {offloaded_layers} layers to the GPU\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLUr7_xjIp6X","executionInfo":{"status":"ok","timestamp":1752158721751,"user_tz":240,"elapsed":47,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"ba6d6b51-e5a1-42bf-98c1-1e713e3406ea"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Successfully offloaded 0 layers to the GPU\n"]}]},{"cell_type":"code","source":["model_path = path+\".models/tinyllama-1.1b-chat-v1.0.Q8_0.gguf\"\n","generator_q8_0 = Llama(\n","    model_path=model_path,\n","    chat_format=\"disabled\",  # This prevents the model from wrapping input in chat templates\n","    n_ctx=2048,\n","    n_threads=2,\n","    n_gpu_layers=n_gpu_layers,\n","    logits_all=True,\n","    verbose=False,\n",")"],"metadata":{"executionInfo":{"status":"ok","timestamp":1752158738951,"user_tz":240,"elapsed":17198,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"id":"a3mR-8v5PPoV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1dd60da0-8a91-4a49-f812-9192155b40aa"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n"]}]},{"cell_type":"code","source":["# Check the number of layers offloaded to the GPU\n","offloaded_layers = generator_q8_0.model_params.n_gpu_layers\n","print(f\"✅ Successfully offloaded {offloaded_layers} layers to the GPU\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752158738989,"user_tz":240,"elapsed":31,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"796aac6a-e9be-4843-c4fb-6ae83c871698","id":"Yb0Ns6CLPPoW"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Successfully offloaded 0 layers to the GPU\n"]}]},{"cell_type":"markdown","source":["# tests"],"metadata":{"id":"Np4sNt4I4aN_"}},{"cell_type":"code","source":["# Define the grammar in GBNF format\n","# This grammar allows for a sequence of numbers (integers or decimals) separated by commas\n","# https://g.co/gemini/share/938d5c086f74\n","gbnf_grammar_str = r'''\n","root   ::= sequence\n","sequence ::= number (\",\" number)*\n","number ::= (\"-\")? ([0-9]+ | [0-9]+ \".\" [0-9]+)\n","'''\n","try:\n","    grammar = LlamaGrammar.from_string(gbnf_grammar_str)\n","    print(\"Strict grammar parsed successfully\")\n","    print(grammar)\n","except Exception as e:\n","    print(f\"Error parsing grammar: {e}\")\n","    grammar = None"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80ofIhhNkDJB","executionInfo":{"status":"ok","timestamp":1752158756959,"user_tz":240,"elapsed":121,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"3e1c2985-9c5b-4d6e-af99-a5fb5c1c3ed1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Strict grammar parsed successfully\n","<llama_cpp.llama_grammar.LlamaGrammar object at 0x7fa75437ec10>\n"]}]},{"cell_type":"code","source":["# Define the prompt with number sequence\n","prompt = \"1.0,2.1,3.3,4.2,5.7,\"\n","#prompt = \"1,2,3,4,5,\""],"metadata":{"id":"nnfAP-KuZTYq","executionInfo":{"status":"ok","timestamp":1752158758578,"user_tz":240,"elapsed":13,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Define parameters for running the model\n","# https://g.co/gemini/share/5e0aed5cf4b8\n","# https://g.co/gemini/share/8e15743e2cd6\n","# https://g.co/gemini/share/1dcee2a72019\n","parameters = {\n","    'max_tokens': 20, # Maximum number of output generated tokens\n","    'logprobs': 1000, # Number of output token-level log probabilities\n","    'grammar': grammar, # Valid grammar for output generation\n","    'temperature': 0.9 # Temperature calibrating the 'surprise of the output generation\n","}"],"metadata":{"id":"mX2kxkYKMCA0","executionInfo":{"status":"ok","timestamp":1752158759455,"user_tz":240,"elapsed":3,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Dictionary with all generators\n","generators = {\n","    'q2_k': generator_q2_k,\n","    'q4_k_m': generator_q4_k_m,\n","    'q6_k': generator_q6_k,\n","    'q8_0': generator_q8_0,\n","}"],"metadata":{"id":"hkEqPKveAJaC","executionInfo":{"status":"ok","timestamp":1752158761364,"user_tz":240,"elapsed":3,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Generate output sequence and logprobs\n","def time_execution(generator, prompt, params):\n","\n","    start_time = time.time()\n","    response = generator(prompt, **params)\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","\n","    choice = response['choices'][0]\n","    text = choice['text']\n","    logprobs = choice['logprobs']\n","\n","    return {'response': text,\n","            'logprobs': logprobs,\n","            'elapsed_time': elapsed_time}"],"metadata":{"id":"2W-THZweH7QT","executionInfo":{"status":"ok","timestamp":1752158762884,"user_tz":240,"elapsed":39,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Run results for all models in dict generators\n","results = {}\n","r = []\n","t = []\n","\n","for key in generators:\n","    results[key] = {}\n","    print(f'### Running {key}')\n","    results[key] = time_execution(generators[key], prompt, parameters)\n","    s = results[key]['response']\n","    print(f'\\tresponse = {s}')\n","    s = results[key]['logprobs']\n","    print(f'\\tlogprobs = {s}')\n","    s = results[key]['elapsed_time']\n","    print(f'\\telapsed_time = {s}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1MH_TlYRaThBc_X_M5x4Xe6YvdXWlduTG"},"id":"IpwYiIk2PQ11","executionInfo":{"status":"ok","timestamp":1752158786276,"user_tz":240,"elapsed":21461,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"8a66756f-5aa3-48a0-cf55-b16ddb954c20"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["len(results['q8_0']['logprobs']['top_logprobs'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0v9uaNlc9vX","executionInfo":{"status":"ok","timestamp":1752158835756,"user_tz":240,"elapsed":12,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"2840c1fa-c442-41a1-eb9c-ac5d9e8d8cf9"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["results['q8_0']['response']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Ho-lynfFzrNU","executionInfo":{"status":"ok","timestamp":1752158902492,"user_tz":240,"elapsed":38,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"bf157108-da82-4db7-d652-c2b7b3c0fbec"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'7.2,8.7,10.2,12.2,14'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["### Save single token log-probabilities"],"metadata":{"id":"DFlpJIeut9w5"}},{"cell_type":"code","source":["logprobs = results['q8_0']['logprobs']['top_logprobs'][0].copy()"],"metadata":{"id":"DW_sCz5cavrA","executionInfo":{"status":"ok","timestamp":1752071564862,"user_tz":240,"elapsed":5,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","file_path = '/content/drive/MyDrive/dev/sapheneia/github/sapheneia/notebooks/marcelo/generator_q8_0_logprobs.json'"],"metadata":{"id":"mjXZg2WQn5Xy","executionInfo":{"status":"ok","timestamp":1752073140085,"user_tz":240,"elapsed":2,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["for key in logprobs:\n","    logprobs[key] = float(logprobs[key])\n","\n","with open(file_path, 'w') as json_file:\n","    json.dump(logprobs, json_file, indent=4)"],"metadata":{"id":"qod6GVJgmng7","executionInfo":{"status":"ok","timestamp":1752071801637,"user_tz":240,"elapsed":9,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["### Save token sequence"],"metadata":{"id":"A00U6JI7uRa-"}},{"cell_type":"code","source":["response = {}\n","\n","for key in generators:\n","    response[key] = results[key]['response']\n","\n","response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kiUM1zDtuUg0","executionInfo":{"status":"ok","timestamp":1752159048854,"user_tz":240,"elapsed":26,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"3667d15c-98eb-480d-88a2-db378cdc29d2"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'q2_k': '10.1,20.2,30.4,40.8,',\n"," 'q4_k_m': '6.8,7.9,8.8,9.8,10.8',\n"," 'q6_k': '7.2,8.8,10.5,12.1,14',\n"," 'q8_0': '7.2,8.7,10.2,12.2,14'}"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["import json\n","\n","file_path = '/content/drive/MyDrive/dev/sapheneia/github/sapheneia/notebooks/marcelo/response_sequences.json'"],"metadata":{"id":"w69N_thcuUjS","executionInfo":{"status":"ok","timestamp":1752159114066,"user_tz":240,"elapsed":4,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["with open(file_path, 'w') as json_file:\n","    json.dump(response, json_file, indent=4)"],"metadata":{"id":"lR7Z1pJCuUmS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wus1CCPZuUon"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Analysis of single token log-probabilities"],"metadata":{"id":"IDF5H33EoFp6"}},{"cell_type":"code","source":["# Load sample logprobs for analysis\n","import json\n","\n","file_path = '/content/drive/MyDrive/dev/sapheneia/github/sapheneia/notebooks/marcelo/generator_q8_0_logprobs.json'\n","\n","logprobs = {}\n","\n","try:\n","    with open(file_path, 'r') as json_file:\n","        logprobs = json.load(json_file)\n","    print(f\"Dictionary loaded from {file_path}:\")\n","    print(logprobs)\n","except FileNotFoundError:\n","    print(f\"Error: The file {file_path} was not found.\")\n","except json.JSONDecodeError:\n","    print(f\"Error: Could not decode JSON from {file_path}.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsomXnGcnjjD","executionInfo":{"status":"ok","timestamp":1752071983234,"user_tz":240,"elapsed":4722,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"9808669d-d252-4b78-9418-572ebad50336"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Dictionary loaded from /content/drive/MyDrive/dev/sapheneia/github/sapheneia/notebooks/marcelo/generator_q8_0_logprobs.json:\n","{'6': -0.272904634475708, '7': -2.412665605545044, '5': -3.4727232456207275, '1': -4.10285758972168, '8': -4.194048881530762, '4': -4.7399492263793945, ' ': -4.851360321044922, '2': -5.01570987701416, '\\n': -5.0478715896606445, '3': -5.1466779708862305, '9': -5.572190284729004, ' and': -5.918932914733887, '0': -5.939314842224121, ' etc': -6.749886512756348, '<': -7.024115562438965, 'and': -7.046576499938965, ' or': -7.070944786071777, 'etc': -7.102926254272461, '...': -7.291332244873047, ' ...': -7.644391059875488, '  ': -7.7795610427856445, 'max': -7.819403648376465, ' (': -7.824001312255859, ' .': -7.824521064758301, 'y': -7.828177452087402, ' A': -7.911307334899902, 'n': -8.026654243469238, ' <': -8.069267272949219, 'A': -8.102025032043457, 'a': -8.105005264282227, 'N': -8.14380931854248, ' -': -8.24870777130127, 'x': -8.262267112731934, '*': -8.352938652038574, ' &': -8.429669380187988, 'or': -8.471209526062012, 'min': -8.573104858398438, 'in': -8.630108833312988, 'j': -8.721749305725098, 'C': -8.746384620666504, 'p': -8.808882713317871, ' \\\\': -8.902606964111328, '/': -8.904084205627441, ' P': -8.959794998168945, ' The': -8.976293563842773, ' in': -8.98991584777832, 'r': -9.00290298461914, '\\t': -9.006840705871582, ' N': -9.040607452392578, ' to': -9.04491901397705, 'P': -9.046809196472168, ' \\r': -9.068275451660156, 'f': -9.077790260314941, 'X': -9.08736515045166, '    ': -9.098612785339355, 's': -9.1005220413208, '   ': -9.103039741516113, 'total': -9.139609336853027, ' I': -9.141469955444336, 'np': -9.143524169921875, '‘': -9.175909996032715, 'mean': -9.194310188293457, '\\r': -9.204964637756348, ' y': -9.207110404968262, '                ': -9.225190162658691, '>': -9.228483200073242, ' max': -9.2515869140625, ' C': -9.2522554397583, ' **': -9.257132530212402, 'to': -9.279778480529785, ' >': -9.280627250671387, ' the': -9.282541275024414, 't': -9.284697532653809, \" '\": -9.312108993530273, 'M': -9.321748733520508, ' not': -9.324667930603027, 'se': -9.32726764678955, ' $': -9.327502250671387, 'null': -9.340269088745117, 'k': -9.380906105041504, '**': -9.399096488952637, ' [': -9.404288291931152, 'm': -9.41434383392334, 'e': -9.421496391296387, 'c': -9.425599098205566, 'S': -9.444093704223633, '': -11.977120399475098, 'T': -9.451491355895996, '…': -9.462800025939941, 'B': -9.472679138183594, '?': -9.474570274353027, ' for': -9.49193286895752, 'test': -9.510265350341797, ' +': -9.519383430480957, 'inf': -9.52118968963623, '∞': -9.522602081298828, 'I': -9.556878089904785, ' R': -9.56743049621582, '....': -9.568514823913574, 'the': -9.572144508361816, 'd': -9.580160140991211, ' a': -9.622249603271484, ' Max': -9.624655723571777, 'R': -9.63188648223877, ' M': -9.640109062194824, 'E': -9.640665054321289, ' respectively': -9.642770767211914, ' /': -9.648652076721191, 'i': -9.652775764465332, '+': -9.659859657287598, ' p': -9.683959007263184, 'NA': -9.700255393981934, '</': -9.704312324523926, ' *': -9.709549903869629, 'g': -9.727530479431152, ' ?': -9.735474586486816, ' \"': -9.745743751525879, 'not': -9.748964309692383, ' but': -9.769505500793457, 'w': -9.79675579071045, ' _': -9.799660682678223, ' is': -9.803991317749023, '”': -9.814007759094238, 'V': -9.831063270568848, ' In': -9.8350248336792, ' r': -9.839966773986816, 'score': -9.841144561767578, ' Total': -9.853009223937988, '(': -9.858250617980957, 'The': -9.858634948730469, ' S': -9.85986042022705, 'b': -9.86267375946045, '..': -9.863533973693848, 'id': -9.864524841308594, 'Y': -9.88676929473877, ' are': -9.888175010681152, ' x': -9.889578819274902, ' :': -9.917460441589355, '“': -9.919035911560059, ' then': -9.919845581054688, ' as': -9.920141220092773, 'L': -9.940508842468262, 'Total': -9.951616287231445, ' Ex': -9.953585624694824, 'th': -9.960458755493164, 'pp': -9.968815803527832, 're': -9.975983619689941, ' E': -9.976828575134277, 'sum': -9.978297233581543, ' Re': -9.990750312805176, 'K': -9.994065284729004, 'all': -9.997673988342285, ' which': -9.999236106872559, ' Con': -10.004694938659668, ' Y': -10.008588790893555, 'float': -10.008957862854004, ' #': -10.012316703796387, '     ': -10.015345573425293, '±': -10.036852836608887, ' ,': -10.044581413269043, ' {': -10.04496955871582, ' ‘': -10.066919326782227, ' //': -10.0773286819458, 'list': -10.078197479248047, ' Not': -10.093411445617676, 'l': -10.113812446594238, ' T': -10.115400314331055, '$\\\\': -10.120643615722656, 'high': -10.128754615783691, ':': -10.13554573059082, ' can': -10.1356201171875, 'as': -10.14267635345459, ' `': -10.146568298339844, 'J': -10.147940635681152, 'any': -10.151772499084473, '-': -10.173834800720215, ' n': -10.193854331970215, 'h': -10.195855140686035, '&': -10.197002410888672, 'H': -10.209441184997559, 'pt': -10.215187072753906, ' L': -10.217545509338379, '≥': -10.225258827209473, '       ': -10.227442741394043, 'Z': -10.240360260009766, 'default': -10.241608619689941, '$': -10.253878593444824, 'G': -10.260527610778809, 'In': -10.264470100402832, 'Max': -10.265057563781738, 'new': -10.266976356506348, ' %': -10.273096084594727, 'but': -10.284403800964355, '_': -10.287371635437012, 'count': -10.300519943237305, ' mean': -10.326549530029297, ' Mean': -10.328079223632812, ' X': -10.331131935119629, ' F': -10.350014686584473, 'which': -10.350432395935059, '      ': -10.359036445617676, ' min': -10.365777015686035, 'F': -10.378547668457031, ' )': -10.389669418334961, 'aver': -10.389681816101074, 'other': -10.39144229888916, 'user': -10.39314079284668, 'ad': -10.395787239074707, 'dev': -10.396012306213379, 'None': -10.411377906799316, '${': -10.413923263549805, '.': -10.418540954589844, ' Output': -10.432199478149414, 'num': -10.439576148986816, ' average': -10.446118354797363, 'z': -10.44769287109375, 'value': -10.452164649963379, ' Rec': -10.457706451416016, ' j': -10.468903541564941, 'Inf': -10.474954605102539, 'step': -10.47701644897461, 'ex': -10.478863716125488, 'for': -10.492218971252441, ' do': -10.506771087646484, 'map': -10.51668930053711, ' so': -10.54057788848877, ' all': -10.542381286621094, ' =': -10.542502403259277, '...]': -10.543472290039062, 'six': -10.561296463012695, ' from': -10.563570976257324, 'res': -10.573116302490234, ' K': -10.57861328125, 'de': -10.57993221282959, 'SE': -10.587239265441895, '[': -10.593384742736816, 'latest': -10.602423667907715, ' B': -10.612032890319824, ' …': -10.6192045211792, 'D': -10.623931884765625, '        ': -10.62498950958252, 'main': -10.62700080871582, ' J': -10.631998062133789, 'un': -10.636141777038574, ' with': -10.641246795654297, 'over': -10.646327018737793, 'none': -10.6472749710083, ' G': -10.65051555633545, ' total': -10.653509140014648, 'standard': -10.655705451965332, 'AC': -10.658596992492676, ' @': -10.658659934997559, 'en': -10.661528587341309, 'scale': -10.661849975585938, 'both': -10.666234016418457, 'an': -10.667290687561035, 'Re': -10.671658515930176, ' Av': -10.675557136535645, ' W': -10.677510261535645, 'rat': -10.701558113098145, ' t': -10.713391304016113, '...)': -10.716439247131348, 'nan': -10.72659683227539, ' H': -10.73289966583252, ' --': -10.73573112487793, ' =>': -10.73682975769043, ' e': -10.742142677307129, 'start': -10.7500638961792, 'U': -10.755054473876953, 'Σ': -10.755867004394531, ' And': -10.756385803222656, 'W': -10.768463134765625, ' This': -10.774447441101074, ' Inf': -10.781874656677246, '--': -10.781983375549316, 'unknown': -10.794835090637207, ' where': -10.796147346496582, 'fe': -10.797515869140625, 'sin': -10.80993938446045, ' it': -10.81259822845459, 'oth': -10.814162254333496, 'Me': -10.8212308883667, 'do': -10.822303771972656, ' others': -10.825078964233398, 'can': -10.830809593200684, 'last': -10.840481758117676, ' Se': -10.842315673828125, 'no': -10.8461332321167, ' Can': -10.84726619720459, 'am': -10.848750114440918, 'sm': -10.849356651306152, ' g': -10.853179931640625, 'Δ': -10.855929374694824, ' k': -10.857547760009766, ' We': -10.860755920410156, 'out': -10.86085033416748, ' at': -10.862481117248535, '>=': -10.863916397094727, 'av': -10.872185707092285, ' Ab': -10.872350692749023, ' It': -10.873333930969238, ' s': -10.876795768737793, 'final': -10.8837308883667, 'NULL': -10.885451316833496, 'sc': -10.889730453491211, 'ass': -10.889907836914062, 'name': -10.89334774017334, ' Use': -10.894552230834961, '........': -10.896368980407715, ' Other': -10.897913932800293, 'year': -10.903363227844238, 'Met': -10.905008316040039, ' You': -10.907599449157715, ' D': -10.909131050109863, ' Z': -10.911170959472656, ' m': -10.916218757629395, ' Res': -10.918057441711426, ' Test': -10.920867919921875, ' i': -10.923081398010254, '’': -10.926141738891602, ' on': -10.926189422607422, '         ': -10.926316261291504, ' Cal': -10.926819801330566, 'plus': -10.928914070129395, ' b': -10.93113899230957, 'under': -10.934159278869629, 'Over': -10.934636116027832, ' V': -10.940220832824707, 'temp': -10.940360069274902, 'data': -10.948447227478027, ' by': -10.94925594329834, 'AB': -10.9531831741333, '),': -10.958205223083496, '≤': -10.958343505859375, '=': -10.961211204528809, 'he': -10.966965675354004, '—': -10.968153953552246, 'array': -10.972502708435059, ' ]': -10.97329044342041, 'sun': -10.977738380432129, \"':\": -10.980631828308105, 'more': -10.983743667602539, 'std': -10.984505653381348, '、': -10.984633445739746, 'Not': -10.994416236877441, 'make': -10.996596336364746, ' “': -10.99756908416748, ' f': -11.000722885131836, '*/': -11.004377365112305, ' any': -11.004916191101074, 'per': -11.00818157196045, 'cr': -11.010441780090332, ' return': -11.013798713684082, ' sun': -11.017988204956055, ' Sunday': -11.0184326171875, ' inf': -11.019021987915039, ' Col': -11.019623756408691, ' </': -11.022780418395996, 'output': -11.02399730682373, '^': -11.024897575378418, ' |': -11.028396606445312, ' These': -11.029091835021973, 'st': -11.034143447875977, 'hr': -11.0348482131958, 'optional': -11.036441802978516, ' $\\\\': -11.04044246673584, ' w': -11.0438871383667, 'ab': -11.044960975646973, '            ': -11.048369407653809, ' speed': -11.050347328186035, 'μ': -11.050769805908203, 'end': -11.052865982055664, ']': -11.05687141418457, ' sum': -11.057063102722168, ' l': -11.060187339782715, 'vs': -11.060314178466797, ' All': -11.062466621398926, '],': -11.062637329101562, ' score': -11.073018074035645, 'item': -11.076385498046875, 'Ex': -11.076411247253418, ' &&': -11.077744483947754, 'this': -11.082855224609375, ' What': -11.085203170776367, '#': -11.089092254638672, 'above': -11.089926719665527, 'you': -11.091119766235352, '```': -11.092782974243164, ' se': -11.093435287475586, ' Gener': -11.093718528747559, 'auto': -11.094534873962402, 'so': -11.096550941467285, ' En': -11.09907341003418, '...,': -11.107182502746582, '\\\\\\\\': -11.110679626464844, 'lower': -11.111652374267578, 'Ab': -11.113481521606445, '              ': -11.12285327911377, 'Res': -11.127399444580078, ' U': -11.13452434539795, ' To': -11.13941478729248, \"')\": -11.140143394470215, ' et': -11.141087532043457, ')': -11.1415433883667, 'v': -11.141803741455078, ' Cont': -11.142417907714844, 'free': -11.145903587341309, '//': -11.157621383666992, ' null': -11.160691261291504, ' must': -11.161345481872559, 'Q': -11.162257194519043, ' Ad': -11.1624174118042, 'EC': -11.164899826049805, 'must': -11.166984558105469, 'range': -11.167250633239746, ' Then': -11.174714088439941, ' may': -11.175647735595703, 'best': -11.175917625427246, 'reduce': -11.178624153137207, '≈': -11.179047584533691, 'Rec': -11.18686580657959, ' you': -11.188353538513184, ' \\\\\\\\': -11.191411018371582, ' Conc': -11.19274616241455, ' Min': -11.19482707977295, ' No': -11.194969177246094, '*.': -11.195099830627441, 'MAX': -11.206196784973145, ' this': -11.210424423217773, 'ans': -11.214093208312988, '%': -11.220993995666504, '}': -11.221179008483887, '??': -11.221512794494629, ' Af': -11.222830772399902, 'each': -11.224658012390137, 'mm': -11.22976016998291, ' Red': -11.231822967529297, 'ms': -11.23312759399414, 'tot': -11.24019718170166, 'from': -11.250635147094727, 'pc': -11.255061149597168, ' Over': -11.256583213806152, 'error': -11.257957458496094, 'height': -11.261039733886719, ' An': -11.261296272277832, ' More': -11.261519432067871, ' ..': -11.262486457824707, ' could': -11.263016700744629, 'pr': -11.263653755187988, '，': -11.268177032470703, ' List': -11.271635055541992, ' en': -11.272759437561035, 'List': -11.280292510986328, ' d': -11.280574798583984, 'my': -11.281693458557129, ' id': -11.283964157104492, 'And': -11.285283088684082, 'den': -11.286397933959961, 'example': -11.28686237335205, ' test': -11.288407325744629, 'Con': -11.289637565612793, ' un': -11.291939735412598, ' O': -11.292222023010254, 'q': -11.296347618103027, 'US': -11.302083969116211, 'where': -11.302999496459961, 'with': -11.303640365600586, 'double': -11.320496559143066, ' have': -11.322162628173828, '***': -11.325197219848633, 'is': -11.32520866394043, 'get': -11.327360153198242, 'IP': -11.330174446105957, ' will': -11.335134506225586, ' more': -11.335444450378418, 'return': -11.336806297302246, ' Sum': -11.337628364562988, 'page': -11.340947151184082, \"',\": -11.343476295471191, ' u': -11.345136642456055, 'im': -11.345574378967285, ' >=': -11.345738410949707, 'nd': -11.348862648010254, 'Other': -11.351286888122559, ' over': -11.352469444274902, 'ear': -11.356504440307617, '|': -11.358540534973145, ' was': -11.361626625061035, 'Un': -11.36436653137207, ' c': -11.365325927734375, 'sub': -11.36617660522461, ' Med': -11.366528511047363, '](': -11.366899490356445, ' ...)': -11.373477935791016, 'title': -11.374336242675781, ' Or': -11.375147819519043, 'now': -11.377358436584473, ' o': -11.378166198730469, 'Ad': -11.379256248474121, 'u': -11.382729530334473, ' followed': -11.392512321472168, 'CR': -11.396697044372559, ',': -11.398139953613281, ' above': -11.398198127746582, ' Cl': -11.398909568786621, ' h': -11.401022911071777, ' ),': -11.401910781860352, ' an': -11.40279769897461, 'read': -11.403165817260742, 'Min': -11.405438423156738, 'eps': -11.408812522888184, ' NR': -11.410735130310059, '):': -11.412074089050293, ' <-': -11.413742065429688, '（': -11.4154052734375, ' Any': -11.417750358581543, ' Read': -11.419333457946777, 'index': -11.4216947555542, 'O': -11.425572395324707, ' Which': -11.42929744720459, ' For': -11.435954093933105, 'else': -11.436490058898926, ' ->': -11.439017295837402, ' value': -11.4393949508667, '---': -11.44081974029541, ' none': -11.4414701461792, 'Or': -11.44448184967041, ' float': -11.445076942443848, 'post': -11.451842308044434, 'by': -11.452936172485352, 'speed': -11.452975273132324, 'it': -11.45665454864502, ' -->': -11.457046508789062, 'High': -11.461962699890137, ';': -11.462868690490723, 'ay': -11.46387767791748, ' Error': -11.466174125671387, ' increase': -11.466389656066895, '##': -11.467690467834473, 'then': -11.467904090881348, 'NR': -11.473052024841309, 'home': -11.474082946777344, 'Th': -11.478424072265625, 'non': -11.479219436645508, 'An': -11.485031127929688, ' Value': -11.487906455993652, ' maximum': -11.49093246459961, 'old': -11.492362022399902, ' Mer': -11.4933443069458, 'first': -11.494410514831543, 'inst': -11.498185157775879, ' VI': -11.49837875366211, ' Speed': -11.499119758605957, 'RE': -11.501517295837402, '等': -11.501627922058105, ' minimum': -11.504171371459961, ' ;': -11.504932403564453, 'break': -11.507277488708496, '∑': -11.507290840148926, 'current': -11.511045455932617, ' Th': -11.511284828186035, './': -11.518685340881348, 'NaN': -11.523032188415527, '?:': -11.5260591506958, '####': -11.533295631408691, ' }': -11.533854484558105, '@': -11.53640365600586, 'deg': -11.538561820983887, ' both': -11.539302825927734, 'rem': -11.539420127868652, 'comb': -11.54454231262207, 'sec': -11.544795989990234, ' https': -11.545825958251953, 'est': -11.548368453979492, 'month': -11.548396110534668, 'dis': -11.55128002166748, 'met': -11.552849769592285, 'root': -11.554550170898438, ' Sc': -11.556593894958496, 'ca': -11.557374954223633, 'Net': -11.558300971984863, 'on': -11.560011863708496, '\">': -11.561713218688965, 'cost': -11.563410758972168, 'Test': -11.566964149475098, '：': -11.567723274230957, 'Com': -11.568636894226074, ' np': -11.57055950164795, 'No': -11.571734428405762, 'rec': -11.572216987609863, '<=': -11.576371192932129, ' including': -11.578953742980957, ' if': -11.582784652709961, 'acc': -11.583465576171875, 'steps': -11.58432674407959, 'maxim': -11.59070110321045, ' before': -11.592144966125488, 'Col': -11.592568397521973, 'show': -11.593372344970703, 'options': -11.599058151245117, ' Pr': -11.600031852722168, '$$': -11.600886344909668, ' under': -11.603407859802246, ' Trans': -11.604552268981934, 'inch': -11.608124732971191, ' SE': -11.610089302062988, ' that': -11.61324405670166, 'Final': -11.6177339553833, '          ': -11.62094783782959, 'https': -11.621492385864258, ' user': -11.6216402053833, 'alpha': -11.622621536254883, 'ts': -11.625954627990723, ' New': -11.627373695373535, 'col': -11.631795883178711, 'at': -11.6325044631958, 'we': -11.634766578674316, 'option': -11.635457992553711, ' default': -11.636832237243652, 'slow': -11.63720989227295, ' None': -11.637310028076172, 'inc': -11.638418197631836, '},': -11.639575004577637, ' How': -11.641389846801758, 'na': -11.643567085266113, '.....': -11.644477844238281, ' while': -11.648155212402344, ' RE': -11.648417472839355, 'full': -11.649955749511719, 'µ': -11.650595664978027, '           ': -11.650945663452148, 'et': -11.652442932128906, 'All': -11.653739929199219, ' Make': -11.654280662536621, 'order': -11.65495491027832, '<-': -11.655309677124023, 'soft': -11.656169891357422, 'λ': -11.657238006591797, 'This': -11.658696174621582, 'Av': -11.658998489379883, ' ---': -11.659940719604492, ' use': -11.66081714630127, ' re': -11.661364555358887, ' cannot': -11.66213607788086, 'New': -11.66492748260498, 'INF': -11.6665620803833, 'some': -11.66733455657959, 'rc': -11.668488502502441, \"';\": -11.6703462600708, 'ac': -11.675442695617676, 'device': -11.677721977233887, ' Cost': -11.67891788482666, ' NA': -11.68028450012207, 'Se': -11.6812744140625, 'Tr': -11.68148136138916, 'dens': -11.682393074035645, ' Me': -11.682504653930664, ' Inc': -11.682721138000488, 'ip': -11.683357238769531, 'ND': -11.684025764465332, ' get': -11.684746742248535, 'items': -11.68516731262207, ' Add': -11.690580368041992, '->': -11.694206237792969, 'duration': -11.702091217041016, 'don': -11.702107429504395, 'o': -11.703370094299316, 'fd': -11.706637382507324, 'AN': -11.707136154174805, ' make': -11.707372665405273, ' Tr': -11.707769393920898, 'normal': -11.707932472229004, 'es': -11.709261894226074, '))': -11.713051795959473, 'cd': -11.717162132263184, ' no': -11.72414493560791, 'ec': -11.726738929748535, '`': -11.726984024047852, 'Step': -11.727104187011719, ' ||': -11.727765083312988, ' other': -11.728199005126953, 'add': -11.728302955627441, ' list': -11.72834587097168, 'mod': -11.72911262512207, ' High': -11.730193138122559, 'You': -11.731805801391602, ' But': -11.735503196716309, '((': -11.73651123046875, ' Comput': -11.736769676208496, 'Error': -11.737552642822266, 'cou': -11.73778247833252, ' Le': -11.737899780273438, 'Can': -11.743098258972168, 'mid': -11.744211196899414, 'α': -11.747208595275879, 'sd': -11.747750282287598, '(.': -11.749723434448242, ' Enter': -11.751704216003418, 'We': -11.753766059875488, ' Inter': -11.75671672821045, 'result': -11.757193565368652, 'Count': -11.762129783630371, '................': -11.762718200683594, 'beta': -11.763916015625, 'ff': -11.76495361328125, ').': -11.765480995178223, 'only': -11.76577377319336, 'bottom': -11.766217231750488, ' z': -11.766237258911133, 'weight': -11.767720222473145, ');': -11.772459983825684, ' new': -11.773682594299316, 'Any': -11.773985862731934, ' of': -11.778220176696777, ' Example': -11.779467582702637, ' latest': -11.783808708190918, 'blue': -11.783856391906738, 'low': -11.783957481384277, 'med': -11.786293029785156, 'cont': -11.790389060974121, ' There': -11.792521476745605, 'pd': -11.79784107208252, 'σ': -11.803742408752441, 'your': -11.804827690124512, 'θ': -11.80865478515625, '???': -11.808822631835938, '----------------': -11.809584617614746, 'level': -11.812641143798828, 'close': -11.814689636230469, ' –': -11.816278457641602, 'print': -11.817923545837402, 'sh': -11.818161964416504, ' Rat': -11.820433616638184, 'cl': -11.821574211120605, 'through': -11.82413101196289, 'What': -11.82471752166748, 'Value': -11.825159072875977, ' Sun': -11.834077835083008, '{': -11.834668159484863, 'mov': -11.835793495178223, 'label': -11.840685844421387, '])': -11.841157913208008, '~': -11.841391563415527, ' Q': -11.846746444702148, '             ': -11.847752571105957, 'fold': -11.849663734436035, 'π': -11.851470947265625, ' see': -11.852653503417969, ' CA': -11.85533618927002, '×': -11.856025695800781, ' nor': -11.856201171875, 'bold': -11.86231517791748, 'ES': -11.86566162109375, ' ./': -11.86759090423584, 'open': -11.870189666748047, 'Sm': -11.871377944946289, ' */': -11.8738431930542, ' median': -11.875932693481445, ' /*': -11.87977123260498, 'cf': -11.881209373474121, 'api': -11.883650779724121, '–': -11.886975288391113, ' —': -11.88757610321045, ' NaN': -11.888900756835938, ' mixed': -11.890186309814453, ' ~': -11.890763282775879, 'raw': -11.891763687133789, ' values': -11.892165184020996, '和': -11.89218807220459, 'top': -11.892645835876465, ' <=': -11.894615173339844, ' otherwise': -11.897034645080566, 'md': -11.89909553527832, 'TO': -11.899465560913086, ' step': -11.899848937988281, 'size': -11.900136947631836, 'Cont': -11.900219917297363, \"'.\": -11.902082443237305, ' until': -11.903780937194824, 'Sum': -11.90398120880127, \"'),\": -11.907113075256348, 'ste': -11.908228874206543, ' Met': -11.90854549407959, ' Exper': -11.90872573852539, ' Call': -11.910423278808594, ' User': -11.910945892333984, 'display': -11.91126823425293, ' Where': -11.911378860473633, ' what': -11.911989212036133, '?,': -11.912392616271973, 'up': -11.913505554199219, ' vs': -11.916923522949219, ' start': -11.917569160461426, 'Example': -11.923613548278809, ' six': -11.927026748657227, '$(': -11.927772521972656, '%.': -11.929120063781738, 'ed': -11.929421424865723, 'allow': -11.93603229522705, 'mult': -11.936166763305664, 'string': -11.936837196350098, 'Data': -11.937952041625977, ' Post': -11.941288948059082, 'NN': -11.942238807678223, 'join': -11.942892074584961, ' Black': -11.944289207458496, 'square': -11.944474220275879, 'int': -11.944703102111816, 'Inter': -11.945034980773926, 'It': -11.94705867767334, 'asc': -11.949919700622559, 'net': -11.951539993286133, 'df': -11.95300579071045, ' after': -11.954182624816895, 'Rad': -11.954524040222168, 'Rel': -11.954741477966309, 'multi': -11.95486831665039, ' ....': -11.95859432220459, 'CA': -11.959168434143066, 'To': -11.959334373474121, 'including': -11.959336280822754, 'St': -11.960810661315918, ' Under': -11.965449333190918, '不': -11.967144966125488, 'values': -11.967547416687012, 'tn': -11.969622611999512, 'path': -11.970622062683105, 'me': -11.970968246459961, ' pass': -11.972233772277832, ' St': -11.972564697265625, ' Random': -11.974481582641602, ' ass': -11.974957466125488, 'pop': -11.97516918182373, 'number': -11.979162216186523, 'pub': -11.979412078857422, 'cat': -11.984196662902832, ' per': -11.988390922546387, 'sp': -11.988733291625977, 'java': -11.989425659179688, ' should': -11.990388870239258, '÷': -11.990693092346191, 'nn': -11.991265296936035, ' Ass': -11.991382598876953, 'http': -11.992096900939941, ' Six': -11.993083000183105, 'mu': -11.994954109191895, 'En': -11.996333122253418, ' NULL': -11.998906135559082, 'Al': -11.999716758728027, ' Rel': -12.000964164733887, 'sign': -12.001373291015625, \" ',\": -12.00179386138916, 'User': -12.003663063049316, ' Est': -12.004167556762695, '{\"': -12.010165214538574, '$-': -12.012017250061035, 'pb': -12.012472152709961, 'below': -12.013195991516113, ' Method': -12.013327598571777, '&#': -12.014137268066406, 'follow': -12.017011642456055, ' means': -12.017258644104004, 'Mer': -12.018982887268066, '*,': -12.019577026367188, 'ce': -12.019762992858887, ' AV': -12.025253295898438, ' Im': -12.025846481323242, 'comp': -12.027363777160645, '\\xa0': -12.028464317321777, ' v': -12.028546333312988, 'OR': -12.029220581054688, ' Select': -12.030547142028809, '/*': -12.03072452545166, '其': -12.032008171081543, ' let': -12.033970832824707, ' non': -12.034049034118652, 'small': -12.036385536193848, 'SM': -12.036531448364258, 'SR': -12.036659240722656, ' Get': -12.038397789001465, ' So': -12.041730880737305, ' As': -12.04336166381836, ' Dur': -12.043936729431152, 'SU': -12.045456886291504, ' Main': -12.04609203338623, 'od': -12.046210289001465, 'er': -12.04628849029541, '||': -12.04642105102539, 'Lat': -12.053383827209473, ' below': -12.0537691116333, ' AND': -12.055741310119629, 'pre': -12.057642936706543, 'Dis': -12.058669090270996, ' Must': -12.059157371520996, ' Order': -12.062623977661133, ' CR': -12.063011169433594, 'send': -12.063179969787598, 'gamma': -12.06477165222168, 'Cr': -12.066875457763672, 'Chr': -12.067702293395996, 'split': -12.068002700805664, 'star': -12.068121910095215, 'rs': -12.068681716918945, ' At': -12.068771362304688, 'con': -12.069853782653809, 'js': -12.070128440856934, ' has': -12.072937965393066, ' Default': -12.075618743896484, 'mix': -12.075754165649414, 'dim': -12.076723098754883, 'dog': -12.08130931854248, 'App': -12.081755638122559, 'drop': -12.08292007446289, ' Calcul': -12.083320617675781, ' each': -12.083544731140137, 'ml': -12.083687782287598, 'dot': -12.08422565460205, '⋅': -12.084821701049805, 'of': -12.084979057312012, 'something': -12.085226058959961, 'cm': -12.085758209228516, 'power': -12.087957382202148, 'round': -12.089248657226562, 'app': -12.089694023132324, ' ***': -12.089837074279785, ' Ste': -12.092388153076172, 'push': -12.09283447265625, 'trans': -12.093306541442871, '...\"': -12.094416618347168, 'da': -12.095170021057129, 'regular': -12.095320701599121, ' Male': -12.097963333129883, ' index': -12.09882926940918, 'sq': -12.098962783813477, '数': -12.09907341003418, 'random': -12.10109806060791, 'after': -12.102692604064941, '--------': -12.103486061096191, \"'''\": -12.103689193725586, ' free': -12.104767799377441, ' Step': -12.105799674987793, 'ma': -12.108404159545898, 'sorted': -12.108441352844238, 'Optional': -12.111838340759277, ' Non': -12.112065315246582, 'oun': -12.11417007446289, ' Data': -12.116097450256348, ' Index': -12.116390228271484, '!': -12.116634368896484, '}}': -12.118457794189453, 'NO': -12.122489929199219, 'δ': -12.122539520263672, ' Un': -12.124112129211426, ' Edit': -12.124241828918457, '($': -12.124615669250488, ' ${': -12.12506103515625, '\\u3000': -12.125826835632324, 'fb': -12.126049041748047, ' Input': -12.126822471618652, 'call': -12.12722396850586, 'ada': -12.129125595092773, ' too': -12.129593849182129, 'lat': -12.129948616027832, 'html': -12.130374908447266, 'Output': -12.130645751953125, ' high': -12.132901191711426, 'β': -12.133191108703613, ' Do': -12.134435653686523, 'ae': -12.134857177734375, 'pass': -12.135348320007324, 'UN': -12.13546085357666, '£': -12.1386137008667, '\\u200b': -12.139460563659668, 'pi': -12.144304275512695, 'usage': -12.144315719604492, 'sol': -12.145378112792969, ' skip': -12.146872520446777, 'EN': -12.147029876708984, ' q': -12.15025520324707, ' Array': -12.151558876037598, ' Prom': -12.152596473693848, ' Ens': -12.152630805969238, 'linux': -12.152810096740723, 'npm': -12.152969360351562, 'ID': -12.154568672180176, 'ST': -12.156912803649902, ' Sy': -12.157273292541504, 'AD': -12.15883731842041, 'tr': -12.159770011901855, 'dist': -12.161100387573242, ' double': -12.162544250488281, 'He': -12.163104057312012}\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"metadata":{"id":"jbIuwx-dtGAM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logprobs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpywBjXRmnjc","executionInfo":{"status":"ok","timestamp":1752071986917,"user_tz":240,"elapsed":87,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"78d8e752-a9da-40ba-a45b-259c4631d7ea"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'6': -0.272904634475708,\n"," '7': -2.412665605545044,\n"," '5': -3.4727232456207275,\n"," '1': -4.10285758972168,\n"," '8': -4.194048881530762,\n"," '4': -4.7399492263793945,\n"," ' ': -4.851360321044922,\n"," '2': -5.01570987701416,\n"," '\\n': -5.0478715896606445,\n"," '3': -5.1466779708862305,\n"," '9': -5.572190284729004,\n"," ' and': -5.918932914733887,\n"," '0': -5.939314842224121,\n"," ' etc': -6.749886512756348,\n"," '<': -7.024115562438965,\n"," 'and': -7.046576499938965,\n"," ' or': -7.070944786071777,\n"," 'etc': -7.102926254272461,\n"," '...': -7.291332244873047,\n"," ' ...': -7.644391059875488,\n"," '  ': -7.7795610427856445,\n"," 'max': -7.819403648376465,\n"," ' (': -7.824001312255859,\n"," ' .': -7.824521064758301,\n"," 'y': -7.828177452087402,\n"," ' A': -7.911307334899902,\n"," 'n': -8.026654243469238,\n"," ' <': -8.069267272949219,\n"," 'A': -8.102025032043457,\n"," 'a': -8.105005264282227,\n"," 'N': -8.14380931854248,\n"," ' -': -8.24870777130127,\n"," 'x': -8.262267112731934,\n"," '*': -8.352938652038574,\n"," ' &': -8.429669380187988,\n"," 'or': -8.471209526062012,\n"," 'min': -8.573104858398438,\n"," 'in': -8.630108833312988,\n"," 'j': -8.721749305725098,\n"," 'C': -8.746384620666504,\n"," 'p': -8.808882713317871,\n"," ' \\\\': -8.902606964111328,\n"," '/': -8.904084205627441,\n"," ' P': -8.959794998168945,\n"," ' The': -8.976293563842773,\n"," ' in': -8.98991584777832,\n"," 'r': -9.00290298461914,\n"," '\\t': -9.006840705871582,\n"," ' N': -9.040607452392578,\n"," ' to': -9.04491901397705,\n"," 'P': -9.046809196472168,\n"," ' \\r': -9.068275451660156,\n"," 'f': -9.077790260314941,\n"," 'X': -9.08736515045166,\n"," '    ': -9.098612785339355,\n"," 's': -9.1005220413208,\n"," '   ': -9.103039741516113,\n"," 'total': -9.139609336853027,\n"," ' I': -9.141469955444336,\n"," 'np': -9.143524169921875,\n"," '‘': -9.175909996032715,\n"," 'mean': -9.194310188293457,\n"," '\\r': -9.204964637756348,\n"," ' y': -9.207110404968262,\n"," '                ': -9.225190162658691,\n"," '>': -9.228483200073242,\n"," ' max': -9.2515869140625,\n"," ' C': -9.2522554397583,\n"," ' **': -9.257132530212402,\n"," 'to': -9.279778480529785,\n"," ' >': -9.280627250671387,\n"," ' the': -9.282541275024414,\n"," 't': -9.284697532653809,\n"," \" '\": -9.312108993530273,\n"," 'M': -9.321748733520508,\n"," ' not': -9.324667930603027,\n"," 'se': -9.32726764678955,\n"," ' $': -9.327502250671387,\n"," 'null': -9.340269088745117,\n"," 'k': -9.380906105041504,\n"," '**': -9.399096488952637,\n"," ' [': -9.404288291931152,\n"," 'm': -9.41434383392334,\n"," 'e': -9.421496391296387,\n"," 'c': -9.425599098205566,\n"," 'S': -9.444093704223633,\n"," '': -11.977120399475098,\n"," 'T': -9.451491355895996,\n"," '…': -9.462800025939941,\n"," 'B': -9.472679138183594,\n"," '?': -9.474570274353027,\n"," ' for': -9.49193286895752,\n"," 'test': -9.510265350341797,\n"," ' +': -9.519383430480957,\n"," 'inf': -9.52118968963623,\n"," '∞': -9.522602081298828,\n"," 'I': -9.556878089904785,\n"," ' R': -9.56743049621582,\n"," '....': -9.568514823913574,\n"," 'the': -9.572144508361816,\n"," 'd': -9.580160140991211,\n"," ' a': -9.622249603271484,\n"," ' Max': -9.624655723571777,\n"," 'R': -9.63188648223877,\n"," ' M': -9.640109062194824,\n"," 'E': -9.640665054321289,\n"," ' respectively': -9.642770767211914,\n"," ' /': -9.648652076721191,\n"," 'i': -9.652775764465332,\n"," '+': -9.659859657287598,\n"," ' p': -9.683959007263184,\n"," 'NA': -9.700255393981934,\n"," '</': -9.704312324523926,\n"," ' *': -9.709549903869629,\n"," 'g': -9.727530479431152,\n"," ' ?': -9.735474586486816,\n"," ' \"': -9.745743751525879,\n"," 'not': -9.748964309692383,\n"," ' but': -9.769505500793457,\n"," 'w': -9.79675579071045,\n"," ' _': -9.799660682678223,\n"," ' is': -9.803991317749023,\n"," '”': -9.814007759094238,\n"," 'V': -9.831063270568848,\n"," ' In': -9.8350248336792,\n"," ' r': -9.839966773986816,\n"," 'score': -9.841144561767578,\n"," ' Total': -9.853009223937988,\n"," '(': -9.858250617980957,\n"," 'The': -9.858634948730469,\n"," ' S': -9.85986042022705,\n"," 'b': -9.86267375946045,\n"," '..': -9.863533973693848,\n"," 'id': -9.864524841308594,\n"," 'Y': -9.88676929473877,\n"," ' are': -9.888175010681152,\n"," ' x': -9.889578819274902,\n"," ' :': -9.917460441589355,\n"," '“': -9.919035911560059,\n"," ' then': -9.919845581054688,\n"," ' as': -9.920141220092773,\n"," 'L': -9.940508842468262,\n"," 'Total': -9.951616287231445,\n"," ' Ex': -9.953585624694824,\n"," 'th': -9.960458755493164,\n"," 'pp': -9.968815803527832,\n"," 're': -9.975983619689941,\n"," ' E': -9.976828575134277,\n"," 'sum': -9.978297233581543,\n"," ' Re': -9.990750312805176,\n"," 'K': -9.994065284729004,\n"," 'all': -9.997673988342285,\n"," ' which': -9.999236106872559,\n"," ' Con': -10.004694938659668,\n"," ' Y': -10.008588790893555,\n"," 'float': -10.008957862854004,\n"," ' #': -10.012316703796387,\n"," '     ': -10.015345573425293,\n"," '±': -10.036852836608887,\n"," ' ,': -10.044581413269043,\n"," ' {': -10.04496955871582,\n"," ' ‘': -10.066919326782227,\n"," ' //': -10.0773286819458,\n"," 'list': -10.078197479248047,\n"," ' Not': -10.093411445617676,\n"," 'l': -10.113812446594238,\n"," ' T': -10.115400314331055,\n"," '$\\\\': -10.120643615722656,\n"," 'high': -10.128754615783691,\n"," ':': -10.13554573059082,\n"," ' can': -10.1356201171875,\n"," 'as': -10.14267635345459,\n"," ' `': -10.146568298339844,\n"," 'J': -10.147940635681152,\n"," 'any': -10.151772499084473,\n"," '-': -10.173834800720215,\n"," ' n': -10.193854331970215,\n"," 'h': -10.195855140686035,\n"," '&': -10.197002410888672,\n"," 'H': -10.209441184997559,\n"," 'pt': -10.215187072753906,\n"," ' L': -10.217545509338379,\n"," '≥': -10.225258827209473,\n"," '       ': -10.227442741394043,\n"," 'Z': -10.240360260009766,\n"," 'default': -10.241608619689941,\n"," '$': -10.253878593444824,\n"," 'G': -10.260527610778809,\n"," 'In': -10.264470100402832,\n"," 'Max': -10.265057563781738,\n"," 'new': -10.266976356506348,\n"," ' %': -10.273096084594727,\n"," 'but': -10.284403800964355,\n"," '_': -10.287371635437012,\n"," 'count': -10.300519943237305,\n"," ' mean': -10.326549530029297,\n"," ' Mean': -10.328079223632812,\n"," ' X': -10.331131935119629,\n"," ' F': -10.350014686584473,\n"," 'which': -10.350432395935059,\n"," '      ': -10.359036445617676,\n"," ' min': -10.365777015686035,\n"," 'F': -10.378547668457031,\n"," ' )': -10.389669418334961,\n"," 'aver': -10.389681816101074,\n"," 'other': -10.39144229888916,\n"," 'user': -10.39314079284668,\n"," 'ad': -10.395787239074707,\n"," 'dev': -10.396012306213379,\n"," 'None': -10.411377906799316,\n"," '${': -10.413923263549805,\n"," '.': -10.418540954589844,\n"," ' Output': -10.432199478149414,\n"," 'num': -10.439576148986816,\n"," ' average': -10.446118354797363,\n"," 'z': -10.44769287109375,\n"," 'value': -10.452164649963379,\n"," ' Rec': -10.457706451416016,\n"," ' j': -10.468903541564941,\n"," 'Inf': -10.474954605102539,\n"," 'step': -10.47701644897461,\n"," 'ex': -10.478863716125488,\n"," 'for': -10.492218971252441,\n"," ' do': -10.506771087646484,\n"," 'map': -10.51668930053711,\n"," ' so': -10.54057788848877,\n"," ' all': -10.542381286621094,\n"," ' =': -10.542502403259277,\n"," '...]': -10.543472290039062,\n"," 'six': -10.561296463012695,\n"," ' from': -10.563570976257324,\n"," 'res': -10.573116302490234,\n"," ' K': -10.57861328125,\n"," 'de': -10.57993221282959,\n"," 'SE': -10.587239265441895,\n"," '[': -10.593384742736816,\n"," 'latest': -10.602423667907715,\n"," ' B': -10.612032890319824,\n"," ' …': -10.6192045211792,\n"," 'D': -10.623931884765625,\n"," '        ': -10.62498950958252,\n"," 'main': -10.62700080871582,\n"," ' J': -10.631998062133789,\n"," 'un': -10.636141777038574,\n"," ' with': -10.641246795654297,\n"," 'over': -10.646327018737793,\n"," 'none': -10.6472749710083,\n"," ' G': -10.65051555633545,\n"," ' total': -10.653509140014648,\n"," 'standard': -10.655705451965332,\n"," 'AC': -10.658596992492676,\n"," ' @': -10.658659934997559,\n"," 'en': -10.661528587341309,\n"," 'scale': -10.661849975585938,\n"," 'both': -10.666234016418457,\n"," 'an': -10.667290687561035,\n"," 'Re': -10.671658515930176,\n"," ' Av': -10.675557136535645,\n"," ' W': -10.677510261535645,\n"," 'rat': -10.701558113098145,\n"," ' t': -10.713391304016113,\n"," '...)': -10.716439247131348,\n"," 'nan': -10.72659683227539,\n"," ' H': -10.73289966583252,\n"," ' --': -10.73573112487793,\n"," ' =>': -10.73682975769043,\n"," ' e': -10.742142677307129,\n"," 'start': -10.7500638961792,\n"," 'U': -10.755054473876953,\n"," 'Σ': -10.755867004394531,\n"," ' And': -10.756385803222656,\n"," 'W': -10.768463134765625,\n"," ' This': -10.774447441101074,\n"," ' Inf': -10.781874656677246,\n"," '--': -10.781983375549316,\n"," 'unknown': -10.794835090637207,\n"," ' where': -10.796147346496582,\n"," 'fe': -10.797515869140625,\n"," 'sin': -10.80993938446045,\n"," ' it': -10.81259822845459,\n"," 'oth': -10.814162254333496,\n"," 'Me': -10.8212308883667,\n"," 'do': -10.822303771972656,\n"," ' others': -10.825078964233398,\n"," 'can': -10.830809593200684,\n"," 'last': -10.840481758117676,\n"," ' Se': -10.842315673828125,\n"," 'no': -10.8461332321167,\n"," ' Can': -10.84726619720459,\n"," 'am': -10.848750114440918,\n"," 'sm': -10.849356651306152,\n"," ' g': -10.853179931640625,\n"," 'Δ': -10.855929374694824,\n"," ' k': -10.857547760009766,\n"," ' We': -10.860755920410156,\n"," 'out': -10.86085033416748,\n"," ' at': -10.862481117248535,\n"," '>=': -10.863916397094727,\n"," 'av': -10.872185707092285,\n"," ' Ab': -10.872350692749023,\n"," ' It': -10.873333930969238,\n"," ' s': -10.876795768737793,\n"," 'final': -10.8837308883667,\n"," 'NULL': -10.885451316833496,\n"," 'sc': -10.889730453491211,\n"," 'ass': -10.889907836914062,\n"," 'name': -10.89334774017334,\n"," ' Use': -10.894552230834961,\n"," '........': -10.896368980407715,\n"," ' Other': -10.897913932800293,\n"," 'year': -10.903363227844238,\n"," 'Met': -10.905008316040039,\n"," ' You': -10.907599449157715,\n"," ' D': -10.909131050109863,\n"," ' Z': -10.911170959472656,\n"," ' m': -10.916218757629395,\n"," ' Res': -10.918057441711426,\n"," ' Test': -10.920867919921875,\n"," ' i': -10.923081398010254,\n"," '’': -10.926141738891602,\n"," ' on': -10.926189422607422,\n"," '         ': -10.926316261291504,\n"," ' Cal': -10.926819801330566,\n"," 'plus': -10.928914070129395,\n"," ' b': -10.93113899230957,\n"," 'under': -10.934159278869629,\n"," 'Over': -10.934636116027832,\n"," ' V': -10.940220832824707,\n"," 'temp': -10.940360069274902,\n"," 'data': -10.948447227478027,\n"," ' by': -10.94925594329834,\n"," 'AB': -10.9531831741333,\n"," '),': -10.958205223083496,\n"," '≤': -10.958343505859375,\n"," '=': -10.961211204528809,\n"," 'he': -10.966965675354004,\n"," '—': -10.968153953552246,\n"," 'array': -10.972502708435059,\n"," ' ]': -10.97329044342041,\n"," 'sun': -10.977738380432129,\n"," \"':\": -10.980631828308105,\n"," 'more': -10.983743667602539,\n"," 'std': -10.984505653381348,\n"," '、': -10.984633445739746,\n"," 'Not': -10.994416236877441,\n"," 'make': -10.996596336364746,\n"," ' “': -10.99756908416748,\n"," ' f': -11.000722885131836,\n"," '*/': -11.004377365112305,\n"," ' any': -11.004916191101074,\n"," 'per': -11.00818157196045,\n"," 'cr': -11.010441780090332,\n"," ' return': -11.013798713684082,\n"," ' sun': -11.017988204956055,\n"," ' Sunday': -11.0184326171875,\n"," ' inf': -11.019021987915039,\n"," ' Col': -11.019623756408691,\n"," ' </': -11.022780418395996,\n"," 'output': -11.02399730682373,\n"," '^': -11.024897575378418,\n"," ' |': -11.028396606445312,\n"," ' These': -11.029091835021973,\n"," 'st': -11.034143447875977,\n"," 'hr': -11.0348482131958,\n"," 'optional': -11.036441802978516,\n"," ' $\\\\': -11.04044246673584,\n"," ' w': -11.0438871383667,\n"," 'ab': -11.044960975646973,\n"," '            ': -11.048369407653809,\n"," ' speed': -11.050347328186035,\n"," 'μ': -11.050769805908203,\n"," 'end': -11.052865982055664,\n"," ']': -11.05687141418457,\n"," ' sum': -11.057063102722168,\n"," ' l': -11.060187339782715,\n"," 'vs': -11.060314178466797,\n"," ' All': -11.062466621398926,\n"," '],': -11.062637329101562,\n"," ' score': -11.073018074035645,\n"," 'item': -11.076385498046875,\n"," 'Ex': -11.076411247253418,\n"," ' &&': -11.077744483947754,\n"," 'this': -11.082855224609375,\n"," ' What': -11.085203170776367,\n"," '#': -11.089092254638672,\n"," 'above': -11.089926719665527,\n"," 'you': -11.091119766235352,\n"," '```': -11.092782974243164,\n"," ' se': -11.093435287475586,\n"," ' Gener': -11.093718528747559,\n"," 'auto': -11.094534873962402,\n"," 'so': -11.096550941467285,\n"," ' En': -11.09907341003418,\n"," '...,': -11.107182502746582,\n"," '\\\\\\\\': -11.110679626464844,\n"," 'lower': -11.111652374267578,\n"," 'Ab': -11.113481521606445,\n"," '              ': -11.12285327911377,\n"," 'Res': -11.127399444580078,\n"," ' U': -11.13452434539795,\n"," ' To': -11.13941478729248,\n"," \"')\": -11.140143394470215,\n"," ' et': -11.141087532043457,\n"," ')': -11.1415433883667,\n"," 'v': -11.141803741455078,\n"," ' Cont': -11.142417907714844,\n"," 'free': -11.145903587341309,\n"," '//': -11.157621383666992,\n"," ' null': -11.160691261291504,\n"," ' must': -11.161345481872559,\n"," 'Q': -11.162257194519043,\n"," ' Ad': -11.1624174118042,\n"," 'EC': -11.164899826049805,\n"," 'must': -11.166984558105469,\n"," 'range': -11.167250633239746,\n"," ' Then': -11.174714088439941,\n"," ' may': -11.175647735595703,\n"," 'best': -11.175917625427246,\n"," 'reduce': -11.178624153137207,\n"," '≈': -11.179047584533691,\n"," 'Rec': -11.18686580657959,\n"," ' you': -11.188353538513184,\n"," ' \\\\\\\\': -11.191411018371582,\n"," ' Conc': -11.19274616241455,\n"," ' Min': -11.19482707977295,\n"," ' No': -11.194969177246094,\n"," '*.': -11.195099830627441,\n"," 'MAX': -11.206196784973145,\n"," ' this': -11.210424423217773,\n"," 'ans': -11.214093208312988,\n"," '%': -11.220993995666504,\n"," '}': -11.221179008483887,\n"," '??': -11.221512794494629,\n"," ' Af': -11.222830772399902,\n"," 'each': -11.224658012390137,\n"," 'mm': -11.22976016998291,\n"," ' Red': -11.231822967529297,\n"," 'ms': -11.23312759399414,\n"," 'tot': -11.24019718170166,\n"," 'from': -11.250635147094727,\n"," 'pc': -11.255061149597168,\n"," ' Over': -11.256583213806152,\n"," 'error': -11.257957458496094,\n"," 'height': -11.261039733886719,\n"," ' An': -11.261296272277832,\n"," ' More': -11.261519432067871,\n"," ' ..': -11.262486457824707,\n"," ' could': -11.263016700744629,\n"," 'pr': -11.263653755187988,\n"," '，': -11.268177032470703,\n"," ' List': -11.271635055541992,\n"," ' en': -11.272759437561035,\n"," 'List': -11.280292510986328,\n"," ' d': -11.280574798583984,\n"," 'my': -11.281693458557129,\n"," ' id': -11.283964157104492,\n"," 'And': -11.285283088684082,\n"," 'den': -11.286397933959961,\n"," 'example': -11.28686237335205,\n"," ' test': -11.288407325744629,\n"," 'Con': -11.289637565612793,\n"," ' un': -11.291939735412598,\n"," ' O': -11.292222023010254,\n"," 'q': -11.296347618103027,\n"," 'US': -11.302083969116211,\n"," 'where': -11.302999496459961,\n"," 'with': -11.303640365600586,\n"," 'double': -11.320496559143066,\n"," ' have': -11.322162628173828,\n"," '***': -11.325197219848633,\n"," 'is': -11.32520866394043,\n"," 'get': -11.327360153198242,\n"," 'IP': -11.330174446105957,\n"," ' will': -11.335134506225586,\n"," ' more': -11.335444450378418,\n"," 'return': -11.336806297302246,\n"," ' Sum': -11.337628364562988,\n"," 'page': -11.340947151184082,\n"," \"',\": -11.343476295471191,\n"," ' u': -11.345136642456055,\n"," 'im': -11.345574378967285,\n"," ' >=': -11.345738410949707,\n"," 'nd': -11.348862648010254,\n"," 'Other': -11.351286888122559,\n"," ' over': -11.352469444274902,\n"," 'ear': -11.356504440307617,\n"," '|': -11.358540534973145,\n"," ' was': -11.361626625061035,\n"," 'Un': -11.36436653137207,\n"," ' c': -11.365325927734375,\n"," 'sub': -11.36617660522461,\n"," ' Med': -11.366528511047363,\n"," '](': -11.366899490356445,\n"," ' ...)': -11.373477935791016,\n"," 'title': -11.374336242675781,\n"," ' Or': -11.375147819519043,\n"," 'now': -11.377358436584473,\n"," ' o': -11.378166198730469,\n"," 'Ad': -11.379256248474121,\n"," 'u': -11.382729530334473,\n"," ' followed': -11.392512321472168,\n"," 'CR': -11.396697044372559,\n"," ',': -11.398139953613281,\n"," ' above': -11.398198127746582,\n"," ' Cl': -11.398909568786621,\n"," ' h': -11.401022911071777,\n"," ' ),': -11.401910781860352,\n"," ' an': -11.40279769897461,\n"," 'read': -11.403165817260742,\n"," 'Min': -11.405438423156738,\n"," 'eps': -11.408812522888184,\n"," ' NR': -11.410735130310059,\n"," '):': -11.412074089050293,\n"," ' <-': -11.413742065429688,\n"," '（': -11.4154052734375,\n"," ' Any': -11.417750358581543,\n"," ' Read': -11.419333457946777,\n"," 'index': -11.4216947555542,\n"," 'O': -11.425572395324707,\n"," ' Which': -11.42929744720459,\n"," ' For': -11.435954093933105,\n"," 'else': -11.436490058898926,\n"," ' ->': -11.439017295837402,\n"," ' value': -11.4393949508667,\n"," '---': -11.44081974029541,\n"," ' none': -11.4414701461792,\n"," 'Or': -11.44448184967041,\n"," ' float': -11.445076942443848,\n"," 'post': -11.451842308044434,\n"," 'by': -11.452936172485352,\n"," 'speed': -11.452975273132324,\n"," 'it': -11.45665454864502,\n"," ' -->': -11.457046508789062,\n"," 'High': -11.461962699890137,\n"," ';': -11.462868690490723,\n"," 'ay': -11.46387767791748,\n"," ' Error': -11.466174125671387,\n"," ' increase': -11.466389656066895,\n"," '##': -11.467690467834473,\n"," 'then': -11.467904090881348,\n"," 'NR': -11.473052024841309,\n"," 'home': -11.474082946777344,\n"," 'Th': -11.478424072265625,\n"," 'non': -11.479219436645508,\n"," 'An': -11.485031127929688,\n"," ' Value': -11.487906455993652,\n"," ' maximum': -11.49093246459961,\n"," 'old': -11.492362022399902,\n"," ' Mer': -11.4933443069458,\n"," 'first': -11.494410514831543,\n"," 'inst': -11.498185157775879,\n"," ' VI': -11.49837875366211,\n"," ' Speed': -11.499119758605957,\n"," 'RE': -11.501517295837402,\n"," '等': -11.501627922058105,\n"," ' minimum': -11.504171371459961,\n"," ' ;': -11.504932403564453,\n"," 'break': -11.507277488708496,\n"," '∑': -11.507290840148926,\n"," 'current': -11.511045455932617,\n"," ' Th': -11.511284828186035,\n"," './': -11.518685340881348,\n"," 'NaN': -11.523032188415527,\n"," '?:': -11.5260591506958,\n"," '####': -11.533295631408691,\n"," ' }': -11.533854484558105,\n"," '@': -11.53640365600586,\n"," 'deg': -11.538561820983887,\n"," ' both': -11.539302825927734,\n"," 'rem': -11.539420127868652,\n"," 'comb': -11.54454231262207,\n"," 'sec': -11.544795989990234,\n"," ' https': -11.545825958251953,\n"," 'est': -11.548368453979492,\n"," 'month': -11.548396110534668,\n"," 'dis': -11.55128002166748,\n"," 'met': -11.552849769592285,\n"," 'root': -11.554550170898438,\n"," ' Sc': -11.556593894958496,\n"," 'ca': -11.557374954223633,\n"," 'Net': -11.558300971984863,\n"," 'on': -11.560011863708496,\n"," '\">': -11.561713218688965,\n"," 'cost': -11.563410758972168,\n"," 'Test': -11.566964149475098,\n"," '：': -11.567723274230957,\n"," 'Com': -11.568636894226074,\n"," ' np': -11.57055950164795,\n"," 'No': -11.571734428405762,\n"," 'rec': -11.572216987609863,\n"," '<=': -11.576371192932129,\n"," ' including': -11.578953742980957,\n"," ' if': -11.582784652709961,\n"," 'acc': -11.583465576171875,\n"," 'steps': -11.58432674407959,\n"," 'maxim': -11.59070110321045,\n"," ' before': -11.592144966125488,\n"," 'Col': -11.592568397521973,\n"," 'show': -11.593372344970703,\n"," 'options': -11.599058151245117,\n"," ' Pr': -11.600031852722168,\n"," '$$': -11.600886344909668,\n"," ' under': -11.603407859802246,\n"," ' Trans': -11.604552268981934,\n"," 'inch': -11.608124732971191,\n"," ' SE': -11.610089302062988,\n"," ' that': -11.61324405670166,\n"," 'Final': -11.6177339553833,\n"," '          ': -11.62094783782959,\n"," 'https': -11.621492385864258,\n"," ' user': -11.6216402053833,\n"," 'alpha': -11.622621536254883,\n"," 'ts': -11.625954627990723,\n"," ' New': -11.627373695373535,\n"," 'col': -11.631795883178711,\n"," 'at': -11.6325044631958,\n"," 'we': -11.634766578674316,\n"," 'option': -11.635457992553711,\n"," ' default': -11.636832237243652,\n"," 'slow': -11.63720989227295,\n"," ' None': -11.637310028076172,\n"," 'inc': -11.638418197631836,\n"," '},': -11.639575004577637,\n"," ' How': -11.641389846801758,\n"," 'na': -11.643567085266113,\n"," '.....': -11.644477844238281,\n"," ' while': -11.648155212402344,\n"," ' RE': -11.648417472839355,\n"," 'full': -11.649955749511719,\n"," 'µ': -11.650595664978027,\n"," '           ': -11.650945663452148,\n"," 'et': -11.652442932128906,\n"," 'All': -11.653739929199219,\n"," ' Make': -11.654280662536621,\n"," 'order': -11.65495491027832,\n"," '<-': -11.655309677124023,\n"," 'soft': -11.656169891357422,\n"," 'λ': -11.657238006591797,\n"," 'This': -11.658696174621582,\n"," 'Av': -11.658998489379883,\n"," ' ---': -11.659940719604492,\n"," ' use': -11.66081714630127,\n"," ' re': -11.661364555358887,\n"," ' cannot': -11.66213607788086,\n"," 'New': -11.66492748260498,\n"," 'INF': -11.6665620803833,\n"," 'some': -11.66733455657959,\n"," 'rc': -11.668488502502441,\n"," \"';\": -11.6703462600708,\n"," 'ac': -11.675442695617676,\n"," 'device': -11.677721977233887,\n"," ' Cost': -11.67891788482666,\n"," ' NA': -11.68028450012207,\n"," 'Se': -11.6812744140625,\n"," 'Tr': -11.68148136138916,\n"," 'dens': -11.682393074035645,\n"," ' Me': -11.682504653930664,\n"," ' Inc': -11.682721138000488,\n"," 'ip': -11.683357238769531,\n"," 'ND': -11.684025764465332,\n"," ' get': -11.684746742248535,\n"," 'items': -11.68516731262207,\n"," ' Add': -11.690580368041992,\n"," '->': -11.694206237792969,\n"," 'duration': -11.702091217041016,\n"," 'don': -11.702107429504395,\n"," 'o': -11.703370094299316,\n"," 'fd': -11.706637382507324,\n"," 'AN': -11.707136154174805,\n"," ' make': -11.707372665405273,\n"," ' Tr': -11.707769393920898,\n"," 'normal': -11.707932472229004,\n"," 'es': -11.709261894226074,\n"," '))': -11.713051795959473,\n"," 'cd': -11.717162132263184,\n"," ' no': -11.72414493560791,\n"," 'ec': -11.726738929748535,\n"," '`': -11.726984024047852,\n"," 'Step': -11.727104187011719,\n"," ' ||': -11.727765083312988,\n"," ' other': -11.728199005126953,\n"," 'add': -11.728302955627441,\n"," ' list': -11.72834587097168,\n"," 'mod': -11.72911262512207,\n"," ' High': -11.730193138122559,\n"," 'You': -11.731805801391602,\n"," ' But': -11.735503196716309,\n"," '((': -11.73651123046875,\n"," ' Comput': -11.736769676208496,\n"," 'Error': -11.737552642822266,\n"," 'cou': -11.73778247833252,\n"," ' Le': -11.737899780273438,\n"," 'Can': -11.743098258972168,\n"," 'mid': -11.744211196899414,\n"," 'α': -11.747208595275879,\n"," 'sd': -11.747750282287598,\n"," '(.': -11.749723434448242,\n"," ' Enter': -11.751704216003418,\n"," 'We': -11.753766059875488,\n"," ' Inter': -11.75671672821045,\n"," 'result': -11.757193565368652,\n"," 'Count': -11.762129783630371,\n"," '................': -11.762718200683594,\n"," 'beta': -11.763916015625,\n"," 'ff': -11.76495361328125,\n"," ').': -11.765480995178223,\n"," 'only': -11.76577377319336,\n"," 'bottom': -11.766217231750488,\n"," ' z': -11.766237258911133,\n"," 'weight': -11.767720222473145,\n"," ');': -11.772459983825684,\n"," ' new': -11.773682594299316,\n"," 'Any': -11.773985862731934,\n"," ' of': -11.778220176696777,\n"," ' Example': -11.779467582702637,\n"," ' latest': -11.783808708190918,\n"," 'blue': -11.783856391906738,\n"," 'low': -11.783957481384277,\n"," 'med': -11.786293029785156,\n"," 'cont': -11.790389060974121,\n"," ' There': -11.792521476745605,\n"," 'pd': -11.79784107208252,\n"," 'σ': -11.803742408752441,\n"," 'your': -11.804827690124512,\n"," 'θ': -11.80865478515625,\n"," '???': -11.808822631835938,\n"," '----------------': -11.809584617614746,\n"," 'level': -11.812641143798828,\n"," 'close': -11.814689636230469,\n"," ' –': -11.816278457641602,\n"," 'print': -11.817923545837402,\n"," 'sh': -11.818161964416504,\n"," ' Rat': -11.820433616638184,\n"," 'cl': -11.821574211120605,\n"," 'through': -11.82413101196289,\n"," 'What': -11.82471752166748,\n"," 'Value': -11.825159072875977,\n"," ' Sun': -11.834077835083008,\n"," '{': -11.834668159484863,\n"," 'mov': -11.835793495178223,\n"," 'label': -11.840685844421387,\n"," '])': -11.841157913208008,\n"," '~': -11.841391563415527,\n"," ' Q': -11.846746444702148,\n"," '             ': -11.847752571105957,\n"," 'fold': -11.849663734436035,\n"," 'π': -11.851470947265625,\n"," ' see': -11.852653503417969,\n"," ' CA': -11.85533618927002,\n"," '×': -11.856025695800781,\n"," ' nor': -11.856201171875,\n"," 'bold': -11.86231517791748,\n"," 'ES': -11.86566162109375,\n"," ' ./': -11.86759090423584,\n"," 'open': -11.870189666748047,\n"," 'Sm': -11.871377944946289,\n"," ' */': -11.8738431930542,\n"," ' median': -11.875932693481445,\n"," ' /*': -11.87977123260498,\n"," 'cf': -11.881209373474121,\n"," 'api': -11.883650779724121,\n"," '–': -11.886975288391113,\n"," ' —': -11.88757610321045,\n"," ' NaN': -11.888900756835938,\n"," ' mixed': -11.890186309814453,\n"," ' ~': -11.890763282775879,\n"," 'raw': -11.891763687133789,\n"," ' values': -11.892165184020996,\n"," '和': -11.89218807220459,\n"," 'top': -11.892645835876465,\n"," ' <=': -11.894615173339844,\n"," ' otherwise': -11.897034645080566,\n"," 'md': -11.89909553527832,\n"," 'TO': -11.899465560913086,\n"," ' step': -11.899848937988281,\n"," 'size': -11.900136947631836,\n"," 'Cont': -11.900219917297363,\n"," \"'.\": -11.902082443237305,\n"," ' until': -11.903780937194824,\n"," 'Sum': -11.90398120880127,\n"," \"'),\": -11.907113075256348,\n"," 'ste': -11.908228874206543,\n"," ' Met': -11.90854549407959,\n"," ' Exper': -11.90872573852539,\n"," ' Call': -11.910423278808594,\n"," ' User': -11.910945892333984,\n"," 'display': -11.91126823425293,\n"," ' Where': -11.911378860473633,\n"," ' what': -11.911989212036133,\n"," '?,': -11.912392616271973,\n"," 'up': -11.913505554199219,\n"," ' vs': -11.916923522949219,\n"," ' start': -11.917569160461426,\n"," 'Example': -11.923613548278809,\n"," ' six': -11.927026748657227,\n"," '$(': -11.927772521972656,\n"," '%.': -11.929120063781738,\n"," 'ed': -11.929421424865723,\n"," 'allow': -11.93603229522705,\n"," 'mult': -11.936166763305664,\n"," 'string': -11.936837196350098,\n"," 'Data': -11.937952041625977,\n"," ' Post': -11.941288948059082,\n"," 'NN': -11.942238807678223,\n"," 'join': -11.942892074584961,\n"," ' Black': -11.944289207458496,\n"," 'square': -11.944474220275879,\n"," 'int': -11.944703102111816,\n"," 'Inter': -11.945034980773926,\n"," 'It': -11.94705867767334,\n"," 'asc': -11.949919700622559,\n"," 'net': -11.951539993286133,\n"," 'df': -11.95300579071045,\n"," ' after': -11.954182624816895,\n"," 'Rad': -11.954524040222168,\n"," 'Rel': -11.954741477966309,\n"," 'multi': -11.95486831665039,\n"," ' ....': -11.95859432220459,\n"," 'CA': -11.959168434143066,\n"," 'To': -11.959334373474121,\n"," 'including': -11.959336280822754,\n"," 'St': -11.960810661315918,\n"," ' Under': -11.965449333190918,\n"," '不': -11.967144966125488,\n"," 'values': -11.967547416687012,\n"," 'tn': -11.969622611999512,\n"," 'path': -11.970622062683105,\n"," 'me': -11.970968246459961,\n"," ' pass': -11.972233772277832,\n"," ' St': -11.972564697265625,\n"," ' Random': -11.974481582641602,\n"," ' ass': -11.974957466125488,\n"," 'pop': -11.97516918182373,\n"," 'number': -11.979162216186523,\n"," 'pub': -11.979412078857422,\n"," 'cat': -11.984196662902832,\n"," ' per': -11.988390922546387,\n"," 'sp': -11.988733291625977,\n"," 'java': -11.989425659179688,\n"," ' should': -11.990388870239258,\n"," '÷': -11.990693092346191,\n"," 'nn': -11.991265296936035,\n"," ' Ass': -11.991382598876953,\n"," 'http': -11.992096900939941,\n"," ' Six': -11.993083000183105,\n"," 'mu': -11.994954109191895,\n"," 'En': -11.996333122253418,\n"," ' NULL': -11.998906135559082,\n"," 'Al': -11.999716758728027,\n"," ' Rel': -12.000964164733887,\n"," 'sign': -12.001373291015625,\n"," \" ',\": -12.00179386138916,\n"," 'User': -12.003663063049316,\n"," ' Est': -12.004167556762695,\n"," '{\"': -12.010165214538574,\n"," '$-': -12.012017250061035,\n"," 'pb': -12.012472152709961,\n"," 'below': -12.013195991516113,\n"," ' Method': -12.013327598571777,\n"," '&#': -12.014137268066406,\n"," 'follow': -12.017011642456055,\n"," ' means': -12.017258644104004,\n"," 'Mer': -12.018982887268066,\n"," '*,': -12.019577026367188,\n"," 'ce': -12.019762992858887,\n"," ' AV': -12.025253295898438,\n"," ' Im': -12.025846481323242,\n"," 'comp': -12.027363777160645,\n"," '\\xa0': -12.028464317321777,\n"," ' v': -12.028546333312988,\n"," 'OR': -12.029220581054688,\n"," ' Select': -12.030547142028809,\n"," '/*': -12.03072452545166,\n"," '其': -12.032008171081543,\n"," ' let': -12.033970832824707,\n"," ' non': -12.034049034118652,\n"," 'small': -12.036385536193848,\n"," 'SM': -12.036531448364258,\n"," 'SR': -12.036659240722656,\n"," ' Get': -12.038397789001465,\n"," ' So': -12.041730880737305,\n"," ' As': -12.04336166381836,\n"," ' Dur': -12.043936729431152,\n"," 'SU': -12.045456886291504,\n"," ' Main': -12.04609203338623,\n"," 'od': -12.046210289001465,\n"," 'er': -12.04628849029541,\n"," '||': -12.04642105102539,\n"," 'Lat': -12.053383827209473,\n"," ' below': -12.0537691116333,\n"," ' AND': -12.055741310119629,\n"," 'pre': -12.057642936706543,\n"," 'Dis': -12.058669090270996,\n"," ' Must': -12.059157371520996,\n"," ' Order': -12.062623977661133,\n"," ' CR': -12.063011169433594,\n"," 'send': -12.063179969787598,\n"," 'gamma': -12.06477165222168,\n"," 'Cr': -12.066875457763672,\n"," 'Chr': -12.067702293395996,\n"," 'split': -12.068002700805664,\n"," 'star': -12.068121910095215,\n"," 'rs': -12.068681716918945,\n"," ' At': -12.068771362304688,\n"," 'con': -12.069853782653809,\n"," 'js': -12.070128440856934,\n"," ' has': -12.072937965393066,\n"," ' Default': -12.075618743896484,\n"," 'mix': -12.075754165649414,\n"," 'dim': -12.076723098754883,\n"," 'dog': -12.08130931854248,\n"," 'App': -12.081755638122559,\n"," 'drop': -12.08292007446289,\n"," ' Calcul': -12.083320617675781,\n"," ' each': -12.083544731140137,\n"," 'ml': -12.083687782287598,\n"," 'dot': -12.08422565460205,\n"," '⋅': -12.084821701049805,\n"," 'of': -12.084979057312012,\n"," 'something': -12.085226058959961,\n"," 'cm': -12.085758209228516,\n"," 'power': -12.087957382202148,\n"," 'round': -12.089248657226562,\n"," 'app': -12.089694023132324,\n"," ' ***': -12.089837074279785,\n"," ' Ste': -12.092388153076172,\n"," 'push': -12.09283447265625,\n"," 'trans': -12.093306541442871,\n"," '...\"': -12.094416618347168,\n"," 'da': -12.095170021057129,\n"," 'regular': -12.095320701599121,\n"," ' Male': -12.097963333129883,\n"," ' index': -12.09882926940918,\n"," 'sq': -12.098962783813477,\n"," '数': -12.09907341003418,\n"," 'random': -12.10109806060791,\n"," 'after': -12.102692604064941,\n"," '--------': -12.103486061096191,\n"," \"'''\": -12.103689193725586,\n"," ' free': -12.104767799377441,\n"," ' Step': -12.105799674987793,\n"," 'ma': -12.108404159545898,\n"," 'sorted': -12.108441352844238,\n"," 'Optional': -12.111838340759277,\n"," ' Non': -12.112065315246582,\n"," 'oun': -12.11417007446289,\n"," ' Data': -12.116097450256348,\n"," ' Index': -12.116390228271484,\n"," '!': -12.116634368896484,\n"," '}}': -12.118457794189453,\n"," 'NO': -12.122489929199219,\n"," 'δ': -12.122539520263672,\n"," ' Un': -12.124112129211426,\n"," ' Edit': -12.124241828918457,\n"," '($': -12.124615669250488,\n"," ' ${': -12.12506103515625,\n"," '\\u3000': -12.125826835632324,\n"," 'fb': -12.126049041748047,\n"," ' Input': -12.126822471618652,\n"," 'call': -12.12722396850586,\n"," 'ada': -12.129125595092773,\n"," ' too': -12.129593849182129,\n"," 'lat': -12.129948616027832,\n"," 'html': -12.130374908447266,\n"," 'Output': -12.130645751953125,\n"," ' high': -12.132901191711426,\n"," 'β': -12.133191108703613,\n"," ' Do': -12.134435653686523,\n"," 'ae': -12.134857177734375,\n"," 'pass': -12.135348320007324,\n"," 'UN': -12.13546085357666,\n"," '£': -12.1386137008667,\n"," '\\u200b': -12.139460563659668,\n"," 'pi': -12.144304275512695,\n"," 'usage': -12.144315719604492,\n"," 'sol': -12.145378112792969,\n"," ' skip': -12.146872520446777,\n"," 'EN': -12.147029876708984,\n"," ' q': -12.15025520324707,\n"," ' Array': -12.151558876037598,\n"," ' Prom': -12.152596473693848,\n"," ' Ens': -12.152630805969238,\n"," 'linux': -12.152810096740723,\n"," 'npm': -12.152969360351562,\n"," 'ID': -12.154568672180176,\n"," 'ST': -12.156912803649902,\n"," ' Sy': -12.157273292541504,\n"," 'AD': -12.15883731842041,\n"," 'tr': -12.159770011901855,\n"," 'dist': -12.161100387573242,\n"," ' double': -12.162544250488281,\n"," 'He': -12.163104057312012}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["tokens = [',','.','-','0','1','2','3','4','5','6','7','8','9']"],"metadata":{"id":"6wCxi2YgojeG","executionInfo":{"status":"ok","timestamp":1752073079771,"user_tz":240,"elapsed":41,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["distribution = pd.DataFrame(logprobs, index=['logprob']).T.reset_index()\n","distribution.columns = ['token','logprob']\n","k = distribution['token'].isin(tokens)\n","distribution = distribution[k].reset_index(drop=True)\n","distribution['prob'] = np.exp(distribution['logprob'])\n","distribution['prob'] = distribution['prob']/distribution['prob'].sum()"],"metadata":{"id":"ZqM2J6QWqkG6","executionInfo":{"status":"ok","timestamp":1752073187968,"user_tz":240,"elapsed":19,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["distribution"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"bLjy5kKwqkJg","executionInfo":{"status":"ok","timestamp":1752073189183,"user_tz":240,"elapsed":39,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"9c489ad7-3c5b-4861-aed8-82abf2851011"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   token    logprob      prob\n","0      6  -0.272905  0.808812\n","1      7  -2.412666  0.095183\n","2      5  -3.472723  0.032975\n","3      1  -4.102858  0.017560\n","4      8  -4.194049  0.016029\n","5      4  -4.739949  0.009286\n","6      2  -5.015710  0.007048\n","7      3  -5.146678  0.006183\n","8      9  -5.572190  0.004040\n","9      0  -5.939315  0.002799\n","10     - -10.173835  0.000041\n","11     . -10.418541  0.000032\n","12     , -11.398140  0.000012"],"text/html":["\n","  <div id=\"df-b1c22bd7-9767-4ef0-80e9-fa12740239b3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>token</th>\n","      <th>logprob</th>\n","      <th>prob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>-0.272905</td>\n","      <td>0.808812</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7</td>\n","      <td>-2.412666</td>\n","      <td>0.095183</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>-3.472723</td>\n","      <td>0.032975</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>-4.102858</td>\n","      <td>0.017560</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8</td>\n","      <td>-4.194049</td>\n","      <td>0.016029</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>4</td>\n","      <td>-4.739949</td>\n","      <td>0.009286</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2</td>\n","      <td>-5.015710</td>\n","      <td>0.007048</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>3</td>\n","      <td>-5.146678</td>\n","      <td>0.006183</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>-5.572190</td>\n","      <td>0.004040</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","      <td>-5.939315</td>\n","      <td>0.002799</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>-</td>\n","      <td>-10.173835</td>\n","      <td>0.000041</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>.</td>\n","      <td>-10.418541</td>\n","      <td>0.000032</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>,</td>\n","      <td>-11.398140</td>\n","      <td>0.000012</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1c22bd7-9767-4ef0-80e9-fa12740239b3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b1c22bd7-9767-4ef0-80e9-fa12740239b3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b1c22bd7-9767-4ef0-80e9-fa12740239b3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-1acd95ad-70e4-48ad-a321-de0cca605182\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1acd95ad-70e4-48ad-a321-de0cca605182')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-1acd95ad-70e4-48ad-a321-de0cca605182 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_994040e5-007c-4d98-87d7-c34d34a44953\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('distribution')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_994040e5-007c-4d98-87d7-c34d34a44953 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('distribution');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"distribution","summary":"{\n  \"name\": \"distribution\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \".\",\n          \"0\",\n          \"6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logprob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.246015926935499,\n        \"min\": -11.398139953613281,\n        \"max\": -0.272904634475708,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          -10.418540954589844,\n          -5.939314842224121,\n          -0.272904634475708\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22139047147903185,\n        \"min\": 1.1918438979013982e-05,\n        \"max\": 0.8088121865840643,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          3.1743427433747255e-05,\n          0.002798704208350036,\n          0.8088121865840643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[],"metadata":{"id":"gh152iulrs9F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for token, prob in sorted(step_0_analysis['full_distribution'].items(), key=lambda item: item[1], reverse=True):\n","        if prob > 0.001: # Only print significant probabilities\n","            print(f\"  P('{token}') = {prob:.4f}\")"],"metadata":{"id":"EXUAcjYDoO0W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Abl5S5umoO21"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yhRKcY9qoO5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Odmzw4T8avtt"},"execution_count":null,"outputs":[]}]}