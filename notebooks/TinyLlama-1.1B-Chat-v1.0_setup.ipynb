{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPiwotSzeFzMv9F4BJMM9YV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hRlTry9kRVap"},"outputs":[],"source":["import os"]},{"cell_type":"code","source":["model_path = '/content/drive/MyDrive/dev/llms/TinyLlama-1.1B-Chat-v1.0/'"],"metadata":{"id":"_BKJWR7uSAUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive/',force_remount=True)\n","\n","# Verify that the model folders exist\n","print(\"\\nChecking for model directories...\")\n","if os.path.exists(model_path):\n","    print(f\"Found base directory: {model_path}\")\n","    print(\"Contents:\", os.listdir(model_path))\n","else:\n","    print(f\"ERROR: The directory '{model_path}' was not found.\")\n","    print(\"Please check the folder name and its location in your Google Drive.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sd2gyV7Rsrr","executionInfo":{"status":"ok","timestamp":1749600971017,"user_tz":240,"elapsed":19541,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"7c2d306b-b90f-48fb-ab9a-a171e8a0332a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","\n","Checking for model directories...\n","Found base directory: /content/drive/MyDrive/dev/llms/TinyLlama-1.1B-Chat-v1.0/\n","Contents: ['.git', 'README.md', 'config.json', '.gitattributes', 'eval_results.json', 'generation_config.json', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json', 'tokenizer.model', 'model.safetensors']\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","import torch"],"metadata":{"id":"g_BjCJVFRst5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load tokenizer and model from the local path in Google Drive\n","try:\n","    tokenizer = AutoTokenizer.from_pretrained(model_path)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_path,\n","        torch_dtype=torch.float32,  # Use float32 for CPU\n","        device_map=\"cpu\",\n","    )\n","    print(\"Model loaded successfully!\")\n","except Exception as e:\n","    print(f\"\\n--- ERROR LOADING MODEL ---\")\n","    print(f\"An error occurred: {e}\")\n","    print(\"\\nThis often happens if the model files are incomplete or corrupted.\")\n","    print(\"Please re-check the files in your Google Drive folder and consider re-uploading them if the problem persists.\")\n","    # Stop execution if model loading fails\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TttLLgngSKOe","executionInfo":{"status":"ok","timestamp":1749601074767,"user_tz":240,"elapsed":45945,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"1b70a709-cbfa-4df0-aea3-6bbef92b0858"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded successfully!\n"]}]},{"cell_type":"code","source":["prompt = \"Explain the concept of CPU inference in simple terms.\""],"metadata":{"id":"9v0bAru9SKQu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nRunning inference...\")\n","\n","# Use a pipeline for easy text generation\n","generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","result = generator(prompt, max_new_tokens=100)\n","\n","print(\"\\n--- Model Output ---\")\n","print(result[0]['generated_text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQKcpRgWXjyj","executionInfo":{"status":"ok","timestamp":1749601391703,"user_tz":240,"elapsed":11672,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"c2fb289f-2d62-4b26-d562-2bde21c8787f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["\n","Running inference...\n","\n","--- Model Output ---\n","Explain the concept of CPU inference in simple terms. How does it work and what are its benefits?\n"]}]},{"cell_type":"code","source":["prompt = \"What's the meaning of life?\""],"metadata":{"id":"9KUT1XnGXlUd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nRunning inference...\")\n","\n","# Use a pipeline for easy text generation\n","generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","result = generator(prompt, max_new_tokens=100)\n","\n","print(\"\\n--- Model Output ---\")\n","print(result[0]['generated_text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RJX22FM0Sips","executionInfo":{"status":"ok","timestamp":1749601353758,"user_tz":240,"elapsed":51553,"user":{"displayName":"Marcelo Labre","userId":"11402290200752388716"}},"outputId":"ebc2f375-902a-4f06-b6d7-d422808fdb0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["\n","Running inference...\n","\n","--- Model Output ---\n","What's the meaning of life?\n","\n","Maya: (smiling) That's a tough question. But I do know that we're all here for a reason. Something greater than ourselves. Something to inspire us and guide us. And that's what makes life so beautiful.\n","\n","Sarah: (nodding) You're right. Life is a beautiful journey. A chance to learn, to grow, to make a difference. To find your place in the world.\n","\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"I3xqHTfCVrR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CKBDImZZVrO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"39o7A5ERVrMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mKJfV6T0VrI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mSBF4_KoVrGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iXh1rZO5VrC5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5iweElvdVq_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GBMtYx-ZVq9E"},"execution_count":null,"outputs":[]}]}